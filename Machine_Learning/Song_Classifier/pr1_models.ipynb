{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3e79eb2-6c00-4958-bd7d-8cbc2610efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"Spot_Yt_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463a7473-ff80-4cac-8b1d-5715fef4e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Views</th>\n",
       "      <th>popularity_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.705</td>\n",
       "      <td>-6.679</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.478096</td>\n",
       "      <td>0.772</td>\n",
       "      <td>138.559</td>\n",
       "      <td>12.313316</td>\n",
       "      <td>21.273576</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-5.815</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.045260</td>\n",
       "      <td>0.852</td>\n",
       "      <td>92.761</td>\n",
       "      <td>12.206942</td>\n",
       "      <td>19.761181</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.695</td>\n",
       "      <td>0.923</td>\n",
       "      <td>-3.930</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.041622</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.109751</td>\n",
       "      <td>0.551</td>\n",
       "      <td>108.014</td>\n",
       "      <td>12.279095</td>\n",
       "      <td>18.085187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.689</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-5.810</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.411447</td>\n",
       "      <td>0.062035</td>\n",
       "      <td>0.578</td>\n",
       "      <td>120.423</td>\n",
       "      <td>12.362512</td>\n",
       "      <td>20.286958</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.663</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-8.627</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067472</td>\n",
       "      <td>0.525</td>\n",
       "      <td>167.953</td>\n",
       "      <td>12.739406</td>\n",
       "      <td>20.934936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "0         0.818   0.705    -6.679       0.1770      0.008325   \n",
       "1         0.676   0.703    -5.815       0.0302      0.083330   \n",
       "2         0.695   0.923    -3.930       0.0522      0.041622   \n",
       "3         0.689   0.739    -5.810       0.0260      0.000015   \n",
       "4         0.663   0.694    -8.627       0.1710      0.024985   \n",
       "\n",
       "   Instrumentalness  Liveness  Valence    Tempo  Duration_ms      Views  \\\n",
       "0          0.002327  0.478096    0.772  138.559    12.313316  21.273576   \n",
       "1          0.000687  0.045260    0.852   92.761    12.206942  19.761181   \n",
       "2          0.045833  0.109751    0.551  108.014    12.279095  18.085187   \n",
       "3          0.411447  0.062035    0.578  120.423    12.362512  20.286958   \n",
       "4          0.000000  0.067472    0.525  167.953    12.739406  20.934936   \n",
       "\n",
       "   popularity_class  \n",
       "0                 4  \n",
       "1                 4  \n",
       "2                 2  \n",
       "3                 4  \n",
       "4                 4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ccdf00-19f7-480d-a727-fec077723948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Views\",  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e45b643-1179-449d-8b99-d8e26d3bb6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>popularity_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.705</td>\n",
       "      <td>-6.679</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.478096</td>\n",
       "      <td>0.772</td>\n",
       "      <td>138.559</td>\n",
       "      <td>12.313316</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-5.815</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.045260</td>\n",
       "      <td>0.852</td>\n",
       "      <td>92.761</td>\n",
       "      <td>12.206942</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.695</td>\n",
       "      <td>0.923</td>\n",
       "      <td>-3.930</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.041622</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.109751</td>\n",
       "      <td>0.551</td>\n",
       "      <td>108.014</td>\n",
       "      <td>12.279095</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.689</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-5.810</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.411447</td>\n",
       "      <td>0.062035</td>\n",
       "      <td>0.578</td>\n",
       "      <td>120.423</td>\n",
       "      <td>12.362512</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.663</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-8.627</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067472</td>\n",
       "      <td>0.525</td>\n",
       "      <td>167.953</td>\n",
       "      <td>12.739406</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "0         0.818   0.705    -6.679       0.1770      0.008325   \n",
       "1         0.676   0.703    -5.815       0.0302      0.083330   \n",
       "2         0.695   0.923    -3.930       0.0522      0.041622   \n",
       "3         0.689   0.739    -5.810       0.0260      0.000015   \n",
       "4         0.663   0.694    -8.627       0.1710      0.024985   \n",
       "\n",
       "   Instrumentalness  Liveness  Valence    Tempo  Duration_ms  popularity_class  \n",
       "0          0.002327  0.478096    0.772  138.559    12.313316                 4  \n",
       "1          0.000687  0.045260    0.852   92.761    12.206942                 4  \n",
       "2          0.045833  0.109751    0.551  108.014    12.279095                 2  \n",
       "3          0.411447  0.062035    0.578  120.423    12.362512                 4  \n",
       "4          0.000000  0.067472    0.525  167.953    12.739406                 4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfb825f-016e-4965-b656-c24a11539ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"popularity_class\", \"Views\"], axis=1)\n",
    "y = df[\"popularity_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fbfa79d-7c34-49d9-b841-c5049bed0d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.705</td>\n",
       "      <td>-6.679</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.478096</td>\n",
       "      <td>0.772</td>\n",
       "      <td>138.559</td>\n",
       "      <td>12.313316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.703</td>\n",
       "      <td>-5.815</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.045260</td>\n",
       "      <td>0.852</td>\n",
       "      <td>92.761</td>\n",
       "      <td>12.206942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.695</td>\n",
       "      <td>0.923</td>\n",
       "      <td>-3.930</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.041622</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.109751</td>\n",
       "      <td>0.551</td>\n",
       "      <td>108.014</td>\n",
       "      <td>12.279095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.689</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-5.810</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.411447</td>\n",
       "      <td>0.062035</td>\n",
       "      <td>0.578</td>\n",
       "      <td>120.423</td>\n",
       "      <td>12.362512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.663</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-8.627</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.024985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067472</td>\n",
       "      <td>0.525</td>\n",
       "      <td>167.953</td>\n",
       "      <td>12.739406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "0         0.818   0.705    -6.679       0.1770      0.008325   \n",
       "1         0.676   0.703    -5.815       0.0302      0.083330   \n",
       "2         0.695   0.923    -3.930       0.0522      0.041622   \n",
       "3         0.689   0.739    -5.810       0.0260      0.000015   \n",
       "4         0.663   0.694    -8.627       0.1710      0.024985   \n",
       "\n",
       "   Instrumentalness  Liveness  Valence    Tempo  Duration_ms  \n",
       "0          0.002327  0.478096    0.772  138.559    12.313316  \n",
       "1          0.000687  0.045260    0.852   92.761    12.206942  \n",
       "2          0.045833  0.109751    0.551  108.014    12.279095  \n",
       "3          0.411447  0.062035    0.578  120.423    12.362512  \n",
       "4          0.000000  0.067472    0.525  167.953    12.739406  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c8ea60-e54e-4e6b-906a-f6f31104c93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    4\n",
       "2    2\n",
       "3    4\n",
       "4    4\n",
       "Name: popularity_class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161b9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_model, df_eval = train_test_split(df, test_size=0.2, random_state=42, stratify=df['popularity_class'])\n",
    "\n",
    "\n",
    "X = df_model.drop(columns=['popularity_class', 'Views'])\n",
    "y = df_model['popularity_class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569fa6d1-1cda-4a9b-8a50-67d5f9907a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0: Accuracy = 0.3002\n",
      "Seed 5: Accuracy = 0.3002\n",
      "Seed 10: Accuracy = 0.3002\n",
      "Seed 15: Accuracy = 0.3002\n",
      "Seed 20: Accuracy = 0.3002\n",
      "Seed 25: Accuracy = 0.3002\n",
      "Seed 30: Accuracy = 0.3002\n",
      "Seed 35: Accuracy = 0.3002\n",
      "Seed 40: Accuracy = 0.3002\n",
      "Seed 45: Accuracy = 0.3002\n",
      "Seed 50: Accuracy = 0.3002\n",
      "Seed 55: Accuracy = 0.3002\n",
      "Seed 60: Accuracy = 0.3002\n",
      "Seed 65: Accuracy = 0.3002\n",
      "Seed 70: Accuracy = 0.3002\n",
      "Seed 75: Accuracy = 0.3002\n",
      "Seed 80: Accuracy = 0.3002\n",
      "Seed 85: Accuracy = 0.3002\n",
      "Seed 90: Accuracy = 0.3002\n",
      "Seed 95: Accuracy = 0.3002\n",
      "Seed 100: Accuracy = 0.3002\n",
      "\n",
      "Średnia dokładność: 0.3001675041876047\n",
      "Odchylenie standardowe: 0.0\n"
     ]
    }
   ],
   "source": [
    "# TERAZ JAK JEST TEN SAM TRAIN I TEST WSZĘDZIE TO SEED NIE MA ZNACZENIA\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for seed in range(0, 101, 5):\n",
    "    \n",
    " \n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "   \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "  \n",
    "    accuracies.append(acc)\n",
    "    \n",
    "\n",
    "    print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "print(\"\\nŚrednia dokładność:\", np.mean(accuracies))\n",
    "print(\"Odchylenie standardowe:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96c87991-7137-493e-bcc5-447f39384330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0: Accuracy = 0.3516\n",
      "Seed 10: Accuracy = 0.3444\n",
      "Seed 20: Accuracy = 0.3535\n",
      "Seed 30: Accuracy = 0.3525\n",
      "Seed 40: Accuracy = 0.3597\n",
      "Seed 50: Accuracy = 0.3533\n",
      "Seed 60: Accuracy = 0.3583\n",
      "Seed 70: Accuracy = 0.3549\n",
      "Seed 80: Accuracy = 0.3447\n",
      "Seed 90: Accuracy = 0.3541\n",
      "Seed 100: Accuracy = 0.3549\n",
      "\n",
      "Średnia dokładność: 0.3528910114275968\n",
      "Odchylenie standardowe: 0.004540298770479144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for seed in range(0, 101, 10):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    \n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, n_estimators=100)  \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    " \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "   \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    accuracies.append(acc)\n",
    "    \n",
    " \n",
    "    print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "print(\"\\nŚrednia dokładność:\", np.mean(accuracies))\n",
    "print(\"Odchylenie standardowe:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2ae87813-6f30-4715-bad3-52b0ed5e7220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0: Accuracy = 0.3256\n",
      "Seed 10: Accuracy = 0.3214\n",
      "Seed 20: Accuracy = 0.3326\n",
      "Seed 30: Accuracy = 0.3372\n",
      "Seed 40: Accuracy = 0.3214\n",
      "Seed 50: Accuracy = 0.3447\n",
      "Seed 60: Accuracy = 0.3299\n",
      "Seed 70: Accuracy = 0.3251\n",
      "Seed 80: Accuracy = 0.3267\n",
      "Seed 90: Accuracy = 0.3248\n",
      "Seed 100: Accuracy = 0.3310\n",
      "\n",
      "Średnia dokładność: 0.32913428035379255\n",
      "Odchylenie standardowe: 0.00671473379426042\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for seed in range(0, 101, 10):\n",
    "    \n",
    "\n",
    "    model = XGBClassifier(random_state=42, n_estimators=100, eval_metric='mlogloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    " \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    " \n",
    "    accuracies.append(acc)\n",
    "    \n",
    "\n",
    "    print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nŚrednia dokładność:\", np.mean(accuracies))\n",
    "print(\"Odchylenie standardowe:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9589d3a-9c22-4f3f-8743-3d7f245ef827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\macie\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\macie\\anaconda3\\lib\\site-packages (from lightgbm) (1.11.4)\n",
      "Using cached lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a5ab8ce-2a1e-4362-b931-f2d0afabd11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0: Accuracy = 0.3192\n",
      "Seed 10: Accuracy = 0.3114\n",
      "Seed 20: Accuracy = 0.3198\n",
      "Seed 30: Accuracy = 0.3318\n",
      "Seed 40: Accuracy = 0.3307\n",
      "Seed 50: Accuracy = 0.3337\n",
      "Seed 60: Accuracy = 0.3267\n",
      "Seed 70: Accuracy = 0.3281\n",
      "Seed 80: Accuracy = 0.3093\n",
      "Seed 90: Accuracy = 0.3208\n",
      "Seed 100: Accuracy = 0.3254\n",
      "\n",
      "Średnia dokładność: 0.32335956726200626\n",
      "Odchylenie standardowe: 0.007666002441559606\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for seed in range(0, 101, 10):\n",
    "\n",
    "    \n",
    "\n",
    "    model = LGBMClassifier(random_state=42, verbose=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    " \n",
    "    accuracies.append(acc)\n",
    "    \n",
    "\n",
    "    print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "print(\"\\nŚrednia dokładność:\", np.mean(accuracies))\n",
    "print(\"Odchylenie standardowe:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9fe0f38-1b3c-4088-b7c9-8b570975f17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0: Accuracy = 0.2726\n",
      "Seed 10: Accuracy = 0.2704\n",
      "Seed 20: Accuracy = 0.2753\n",
      "Seed 30: Accuracy = 0.2715\n",
      "Seed 40: Accuracy = 0.2814\n",
      "Seed 50: Accuracy = 0.2632\n",
      "Seed 60: Accuracy = 0.2737\n",
      "Seed 70: Accuracy = 0.2777\n",
      "Seed 80: Accuracy = 0.2653\n",
      "Seed 90: Accuracy = 0.2672\n",
      "Seed 100: Accuracy = 0.2670\n",
      "\n",
      "Średnia dokładność: 0.27138714943592995\n",
      "Odchylenie standardowe: 0.005251397885590583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for seed in range(0, 101, 10):\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=5) \n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "print(\"\\nŚrednia dokładność:\", np.mean(accuracies))\n",
    "print(\"Odchylenie standardowe:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "572143ad-3487-4e00-a12f-4999621a9205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0: Accuracy = 0.2820\n",
      "Seed 10: Accuracy = 0.2876\n",
      "Seed 20: Accuracy = 0.2932\n",
      "Seed 30: Accuracy = 0.2997\n",
      "Seed 40: Accuracy = 0.2991\n",
      "Seed 50: Accuracy = 0.2930\n",
      "Seed 60: Accuracy = 0.3010\n",
      "Seed 70: Accuracy = 0.2863\n",
      "Seed 80: Accuracy = 0.2849\n",
      "Seed 90: Accuracy = 0.2921\n",
      "Seed 100: Accuracy = 0.2825\n",
      "\n",
      "Średnia dokładność: 0.2910260471236081\n",
      "Odchylenie standardowe: 0.006576981939087364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for seed in range(0, 101, 10):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = SVC(random_state=42)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "print(\"\\nŚrednia dokładność:\", np.mean(accuracies))\n",
    "print(\"Odchylenie standardowe:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a2689-685f-431e-ba6e-677b4e3f3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# za dlugo sie laduje - wniosek: nie warto (i nie będziemy) używać grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#parametry\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Najlepsze hiperparametry:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Dokładność na zbiorze testowym: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1b487f-b579-4965-8ee3-693c9c1ea40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 30}\n",
      "Accuracy na zbiorze testowym: 0.3310\n"
     ]
    }
   ],
   "source": [
    "# szukanie najlepszaych parametrow dla random forest  (poprzez random search)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Najlepsze parametry:\", random_search.best_params_)\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy na zbiorze testowym: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d02e8086-8644-4f03-aa9a-ec62430ddde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki dla każdego folda: [0.34036851 0.33411528 0.34785523 0.32774799 0.33076408]\n",
      "Średnia dokładność: 0.3361702165878544\n"
     ]
    }
   ],
   "source": [
    "# walidacja krzyżowa (metody walidacji)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=30,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "print(\"Wyniki dla każdego folda:\", scores)\n",
    "print(\"Średnia dokładność:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "252a031b-756d-4c10-b247-d3b6b2979e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\macie\\anaconda3\\lib\\site-packages (4.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\macie\\anaconda3\\lib\\site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\macie\\anaconda3\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\macie\\anaconda3\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\macie\\anaconda3\\lib\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\macie\\anaconda3\\lib\\site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\macie\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\macie\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\macie\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\macie\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\macie\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\macie\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\macie\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a5c475f4-fd51-48f9-ad92-5c03e9f563b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 14:39:59,132] A new study created in memory with name: no-name-85f83ed7-4778-42dc-a345-38fa3d2bed8b\n",
      "[I 2025-04-22 14:40:00,916] Trial 0 finished with value: 0.33771106941838647 and parameters: {'n_estimators': 70, 'max_depth': 10, 'learning_rate': 0.03153063713184479, 'subsample': 0.9689311074786064, 'colsample_bytree': 0.5667931811160463}. Best is trial 0 with value: 0.33771106941838647.\n",
      "[I 2025-04-22 14:40:04,790] Trial 1 finished with value: 0.33851514339319216 and parameters: {'n_estimators': 287, 'max_depth': 10, 'learning_rate': 0.23893276826721735, 'subsample': 0.8769624989636786, 'colsample_bytree': 0.5957180453543561}. Best is trial 1 with value: 0.33851514339319216.\n",
      "[I 2025-04-22 14:40:07,613] Trial 2 finished with value: 0.34467971053336904 and parameters: {'n_estimators': 198, 'max_depth': 9, 'learning_rate': 0.1877099147852682, 'subsample': 0.5342832293416399, 'colsample_bytree': 0.5146770237202289}. Best is trial 2 with value: 0.34467971053336904.\n",
      "[I 2025-04-22 14:40:10,182] Trial 3 finished with value: 0.34012329134280356 and parameters: {'n_estimators': 240, 'max_depth': 8, 'learning_rate': 0.28945599144698525, 'subsample': 0.8502988815339669, 'colsample_bytree': 0.8733969894158053}. Best is trial 2 with value: 0.34467971053336904.\n",
      "[I 2025-04-22 14:40:10,776] Trial 4 finished with value: 0.30179576521039936 and parameters: {'n_estimators': 151, 'max_depth': 4, 'learning_rate': 0.20535241564174672, 'subsample': 0.7811705761650041, 'colsample_bytree': 0.6714690476743452}. Best is trial 2 with value: 0.34467971053336904.\n",
      "[I 2025-04-22 14:40:11,514] Trial 5 finished with value: 0.33931921736799786 and parameters: {'n_estimators': 66, 'max_depth': 8, 'learning_rate': 0.2231271355606318, 'subsample': 0.8253747599774586, 'colsample_bytree': 0.7312062781046247}. Best is trial 2 with value: 0.34467971053336904.\n",
      "[I 2025-04-22 14:40:13,923] Trial 6 finished with value: 0.34762798177432325 and parameters: {'n_estimators': 174, 'max_depth': 9, 'learning_rate': 0.2560377261618266, 'subsample': 0.7933530779657822, 'colsample_bytree': 0.7938161358712442}. Best is trial 6 with value: 0.34762798177432325.\n",
      "[I 2025-04-22 14:40:17,555] Trial 7 finished with value: 0.3162690967569016 and parameters: {'n_estimators': 278, 'max_depth': 6, 'learning_rate': 0.026874479327776812, 'subsample': 0.8435386373688395, 'colsample_bytree': 0.5737093358283573}. Best is trial 6 with value: 0.34762798177432325.\n",
      "[I 2025-04-22 14:40:19,345] Trial 8 finished with value: 0.33663897078531224 and parameters: {'n_estimators': 73, 'max_depth': 9, 'learning_rate': 0.27570057673559567, 'subsample': 0.5123794966556845, 'colsample_bytree': 0.5582633670213173}. Best is trial 6 with value: 0.34762798177432325.\n",
      "[I 2025-04-22 14:40:21,133] Trial 9 finished with value: 0.33797909407665505 and parameters: {'n_estimators': 123, 'max_depth': 7, 'learning_rate': 0.10052862163288095, 'subsample': 0.8778632338076757, 'colsample_bytree': 0.6728507571816444}. Best is trial 6 with value: 0.34762798177432325.\n",
      "[I 2025-04-22 14:40:22,389] Trial 10 finished with value: 0.3047440364513535 and parameters: {'n_estimators': 195, 'max_depth': 3, 'learning_rate': 0.13627825228074564, 'subsample': 0.667466585319511, 'colsample_bytree': 0.9775860945829492}. Best is trial 6 with value: 0.34762798177432325.\n",
      "[I 2025-04-22 14:40:24,807] Trial 11 finished with value: 0.33529884749396943 and parameters: {'n_estimators': 202, 'max_depth': 6, 'learning_rate': 0.17637844852463994, 'subsample': 0.666133637482997, 'colsample_bytree': 0.8348550526230274}. Best is trial 6 with value: 0.34762798177432325.\n",
      "[I 2025-04-22 14:40:28,885] Trial 12 finished with value: 0.33931921736799786 and parameters: {'n_estimators': 153, 'max_depth': 9, 'learning_rate': 0.15000086066237572, 'subsample': 0.5102943473380913, 'colsample_bytree': 0.810164054225158}. Best is trial 6 with value: 0.34762798177432325.\n",
      "[I 2025-04-22 14:40:32,583] Trial 13 finished with value: 0.34843205574912894 and parameters: {'n_estimators': 230, 'max_depth': 8, 'learning_rate': 0.24655647673524686, 'subsample': 0.6678214741708106, 'colsample_bytree': 0.5037857054411164}. Best is trial 13 with value: 0.34843205574912894.\n",
      "[I 2025-04-22 14:40:37,187] Trial 14 finished with value: 0.34012329134280356 and parameters: {'n_estimators': 241, 'max_depth': 7, 'learning_rate': 0.2579358530584719, 'subsample': 0.6837555725710659, 'colsample_bytree': 0.9343280741150446}. Best is trial 13 with value: 0.34843205574912894.\n",
      "[I 2025-04-22 14:40:41,767] Trial 15 finished with value: 0.33744304476011794 and parameters: {'n_estimators': 229, 'max_depth': 8, 'learning_rate': 0.24346262638017882, 'subsample': 0.5984756750234077, 'colsample_bytree': 0.7531037964595093}. Best is trial 13 with value: 0.34843205574912894.\n",
      "[I 2025-04-22 14:40:42,969] Trial 16 finished with value: 0.31117662824979897 and parameters: {'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.2891377463225745, 'subsample': 0.7355088530215372, 'colsample_bytree': 0.6697101824661462}. Best is trial 13 with value: 0.34843205574912894.\n",
      "[I 2025-04-22 14:40:48,528] Trial 17 finished with value: 0.3505762530152774 and parameters: {'n_estimators': 166, 'max_depth': 10, 'learning_rate': 0.09977757573280396, 'subsample': 0.749331266240034, 'colsample_bytree': 0.7548478711309045}. Best is trial 17 with value: 0.3505762530152774.\n",
      "[I 2025-04-22 14:40:57,280] Trial 18 finished with value: 0.35915304207987137 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.08182917640832042, 'subsample': 0.6047778819288313, 'colsample_bytree': 0.7351802068549158}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:07,276] Trial 19 finished with value: 0.34843205574912894 and parameters: {'n_estimators': 261, 'max_depth': 10, 'learning_rate': 0.07553891761380171, 'subsample': 0.5895890081626269, 'colsample_bytree': 0.8903506675166628}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:10,979] Trial 20 finished with value: 0.3524524256231573 and parameters: {'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.08620501705590876, 'subsample': 0.6014707768388118, 'colsample_bytree': 0.727687559487345}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:14,868] Trial 21 finished with value: 0.34896810506566606 and parameters: {'n_estimators': 116, 'max_depth': 10, 'learning_rate': 0.07825345286290622, 'subsample': 0.5946697863275632, 'colsample_bytree': 0.7300441413513694}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:17,896] Trial 22 finished with value: 0.34950415438220317 and parameters: {'n_estimators': 95, 'max_depth': 10, 'learning_rate': 0.11299842164654722, 'subsample': 0.7230073284879184, 'colsample_bytree': 0.767179068230246}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:21,317] Trial 23 finished with value: 0.3419994639506835 and parameters: {'n_estimators': 149, 'max_depth': 9, 'learning_rate': 0.05926327154672546, 'subsample': 0.5606352402498783, 'colsample_bytree': 0.6365998091756487}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:30,077] Trial 24 finished with value: 0.34950415438220317 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.11857678498895145, 'subsample': 0.6278906495566524, 'colsample_bytree': 0.7064109671017853}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:34,398] Trial 25 finished with value: 0.3521844009648888 and parameters: {'n_estimators': 174, 'max_depth': 9, 'learning_rate': 0.053935987102561644, 'subsample': 0.9536072186515626, 'colsample_bytree': 0.7949882928047378}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:37,755] Trial 26 finished with value: 0.3280621817207183 and parameters: {'n_estimators': 94, 'max_depth': 9, 'learning_rate': 0.01217296105889204, 'subsample': 0.9753787111177565, 'colsample_bytree': 0.8394807978995681}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:40,704] Trial 27 finished with value: 0.3403913160010721 and parameters: {'n_estimators': 216, 'max_depth': 7, 'learning_rate': 0.06144164318821839, 'subsample': 0.9424776135952893, 'colsample_bytree': 0.7835567040247571}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:43,321] Trial 28 finished with value: 0.33663897078531224 and parameters: {'n_estimators': 133, 'max_depth': 8, 'learning_rate': 0.05053959114572657, 'subsample': 0.9340551007629435, 'colsample_bytree': 0.7090135238192324}. Best is trial 18 with value: 0.35915304207987137.\n",
      "[I 2025-04-22 14:41:47,263] Trial 29 finished with value: 0.342267488608952 and parameters: {'n_estimators': 95, 'max_depth': 10, 'learning_rate': 0.03837752004783019, 'subsample': 0.6273030259153358, 'colsample_bytree': 0.869944329952469}. Best is trial 18 with value: 0.35915304207987137.\n",
      "C:\\Users\\macie\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:41:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Najlepsze parametry: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.08182917640832042, 'subsample': 0.6047778819288313, 'colsample_bytree': 0.7351802068549158}\n",
      "\n",
      "Raport końcowy:\n",
      "Accuracy: 0.35915304207987137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.39      0.38       744\n",
      "           1       0.32      0.30      0.31       709\n",
      "           2       0.32      0.31      0.31       766\n",
      "           3       0.36      0.34      0.35       783\n",
      "           4       0.41      0.45      0.43       729\n",
      "\n",
      "    accuracy                           0.36      3731\n",
      "   macro avg       0.36      0.36      0.36      3731\n",
      "weighted avg       0.36      0.36      0.36      3731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# wybor najlepszych parametrow\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "    model = XGBClassifier(\n",
    "        **params,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"\\nNajlepsze parametry:\", best_params)\n",
    "\n",
    "# model XGBoost z uzyciem najlepszych parametrow\n",
    "\n",
    "final_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print(\"\\nRaport końcowy:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2959f28b-5a87-42c0-97ff-f3304a5f4dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Views</th>\n",
       "      <th>popularity_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-8.261</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.281412</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.116894</td>\n",
       "      <td>0.270</td>\n",
       "      <td>76.773</td>\n",
       "      <td>12.388382</td>\n",
       "      <td>18.945402</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-11.325</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.314811</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.064476</td>\n",
       "      <td>0.614</td>\n",
       "      <td>111.003</td>\n",
       "      <td>12.628506</td>\n",
       "      <td>17.804557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-6.767</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.425268</td>\n",
       "      <td>0.056947</td>\n",
       "      <td>0.735</td>\n",
       "      <td>113.456</td>\n",
       "      <td>11.968076</td>\n",
       "      <td>15.845656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-3.599</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.226338</td>\n",
       "      <td>0.543</td>\n",
       "      <td>108.024</td>\n",
       "      <td>12.442519</td>\n",
       "      <td>18.712253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-9.136</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.439544</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.431782</td>\n",
       "      <td>0.296</td>\n",
       "      <td>179.779</td>\n",
       "      <td>12.676814</td>\n",
       "      <td>18.840284</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "4006         0.517   0.428    -8.261       0.0267      0.281412   \n",
       "3161         0.652   0.440   -11.325       0.0271      0.314811   \n",
       "8634         0.835   0.835    -6.767       0.0973      0.015184   \n",
       "7438         0.529   0.894    -3.599       0.0412      0.268499   \n",
       "2238         0.393   0.290    -9.136       0.0385      0.439544   \n",
       "\n",
       "      Instrumentalness  Liveness  Valence    Tempo  Duration_ms      Views  \\\n",
       "4006          0.000175  0.116894    0.270   76.773    12.388382  18.945402   \n",
       "3161          0.000038  0.064476    0.614  111.003    12.628506  17.804557   \n",
       "8634          0.425268  0.056947    0.735  113.456    11.968076  15.845656   \n",
       "7438          0.000005  0.226338    0.543  108.024    12.442519  18.712253   \n",
       "2238          0.000004  0.431782    0.296  179.779    12.676814  18.840284   \n",
       "\n",
       "      popularity_class  \n",
       "4006                 3  \n",
       "3161                 1  \n",
       "8634                 0  \n",
       "7438                 3  \n",
       "2238                 3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9301fa40-4e4e-4eee-8cdd-853d5d861bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = df_model['Views'].quantile([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "df_model['views_0_20'] = (df_model['Views'] <= percentiles[0.2]).astype(int)\n",
    "df_model['views_20_40'] = ((df_model['Views'] > percentiles[0.2]) & (df_model['Views'] <= percentiles[0.4])).astype(int)\n",
    "df_model['views_40_60'] = ((df_model['Views'] > percentiles[0.4]) & (df_model['Views'] <= percentiles[0.6])).astype(int)\n",
    "df_model['views_60_80'] = ((df_model['Views'] > percentiles[0.6]) & (df_model['Views'] <= percentiles[0.8])).astype(int)\n",
    "df_model['views_80_100'] = (df_model['Views'] > percentiles[0.8]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e81a3d7-9b4b-4336-b629-82352acd50ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>Views</th>\n",
       "      <th>popularity_class</th>\n",
       "      <th>views_0_20</th>\n",
       "      <th>views_20_40</th>\n",
       "      <th>views_40_60</th>\n",
       "      <th>views_60_80</th>\n",
       "      <th>views_80_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-8.261</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.281412</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.116894</td>\n",
       "      <td>0.270</td>\n",
       "      <td>76.773</td>\n",
       "      <td>12.388382</td>\n",
       "      <td>18.945402</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-11.325</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.314811</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.064476</td>\n",
       "      <td>0.614</td>\n",
       "      <td>111.003</td>\n",
       "      <td>12.628506</td>\n",
       "      <td>17.804557</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-6.767</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.425268</td>\n",
       "      <td>0.056947</td>\n",
       "      <td>0.735</td>\n",
       "      <td>113.456</td>\n",
       "      <td>11.968076</td>\n",
       "      <td>15.845656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-3.599</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.226338</td>\n",
       "      <td>0.543</td>\n",
       "      <td>108.024</td>\n",
       "      <td>12.442519</td>\n",
       "      <td>18.712253</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-9.136</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.439544</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.431782</td>\n",
       "      <td>0.296</td>\n",
       "      <td>179.779</td>\n",
       "      <td>12.676814</td>\n",
       "      <td>18.840284</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "4006         0.517   0.428    -8.261       0.0267      0.281412   \n",
       "3161         0.652   0.440   -11.325       0.0271      0.314811   \n",
       "8634         0.835   0.835    -6.767       0.0973      0.015184   \n",
       "7438         0.529   0.894    -3.599       0.0412      0.268499   \n",
       "2238         0.393   0.290    -9.136       0.0385      0.439544   \n",
       "\n",
       "      Instrumentalness  Liveness  Valence    Tempo  Duration_ms      Views  \\\n",
       "4006          0.000175  0.116894    0.270   76.773    12.388382  18.945402   \n",
       "3161          0.000038  0.064476    0.614  111.003    12.628506  17.804557   \n",
       "8634          0.425268  0.056947    0.735  113.456    11.968076  15.845656   \n",
       "7438          0.000005  0.226338    0.543  108.024    12.442519  18.712253   \n",
       "2238          0.000004  0.431782    0.296  179.779    12.676814  18.840284   \n",
       "\n",
       "      popularity_class  views_0_20  views_20_40  views_40_60  views_60_80  \\\n",
       "4006                 3           0            0            0            1   \n",
       "3161                 1           0            1            0            0   \n",
       "8634                 0           1            0            0            0   \n",
       "7438                 3           0            0            0            1   \n",
       "2238                 3           0            0            0            1   \n",
       "\n",
       "      views_80_100  \n",
       "4006             0  \n",
       "3161             0  \n",
       "8634             0  \n",
       "7438             0  \n",
       "2238             0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9250edc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "      <th>popularity_class</th>\n",
       "      <th>views_0_20</th>\n",
       "      <th>views_20_40</th>\n",
       "      <th>views_40_60</th>\n",
       "      <th>views_60_80</th>\n",
       "      <th>views_80_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-8.261</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.281412</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.116894</td>\n",
       "      <td>0.270</td>\n",
       "      <td>76.773</td>\n",
       "      <td>12.388382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-11.325</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.314811</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.064476</td>\n",
       "      <td>0.614</td>\n",
       "      <td>111.003</td>\n",
       "      <td>12.628506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-6.767</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.425268</td>\n",
       "      <td>0.056947</td>\n",
       "      <td>0.735</td>\n",
       "      <td>113.456</td>\n",
       "      <td>11.968076</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-3.599</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.226338</td>\n",
       "      <td>0.543</td>\n",
       "      <td>108.024</td>\n",
       "      <td>12.442519</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-9.136</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.439544</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.431782</td>\n",
       "      <td>0.296</td>\n",
       "      <td>179.779</td>\n",
       "      <td>12.676814</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.344299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549854</td>\n",
       "      <td>0.877</td>\n",
       "      <td>120.027</td>\n",
       "      <td>12.235636</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-7.312</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.082501</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.078256</td>\n",
       "      <td>0.665</td>\n",
       "      <td>113.032</td>\n",
       "      <td>12.316352</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11511</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.678</td>\n",
       "      <td>-5.421</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.081580</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.122218</td>\n",
       "      <td>0.583</td>\n",
       "      <td>96.006</td>\n",
       "      <td>12.353751</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.634</td>\n",
       "      <td>-5.941</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.019705</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.254642</td>\n",
       "      <td>0.754</td>\n",
       "      <td>125.250</td>\n",
       "      <td>12.626453</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.806</td>\n",
       "      <td>-7.621</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.098034</td>\n",
       "      <td>0.186480</td>\n",
       "      <td>0.076868</td>\n",
       "      <td>0.887</td>\n",
       "      <td>130.012</td>\n",
       "      <td>12.803557</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14921 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "4006          0.517   0.428    -8.261       0.0267      0.281412   \n",
       "3161          0.652   0.440   -11.325       0.0271      0.314811   \n",
       "8634          0.835   0.835    -6.767       0.0973      0.015184   \n",
       "7438          0.529   0.894    -3.599       0.0412      0.268499   \n",
       "2238          0.393   0.290    -9.136       0.0385      0.439544   \n",
       "...             ...     ...       ...          ...           ...   \n",
       "13877         0.722   0.975    -0.432       0.1420      0.344299   \n",
       "9169          0.969   0.511    -7.312       0.0882      0.082501   \n",
       "11511         0.753   0.678    -5.421       0.0644      0.081580   \n",
       "4788          0.780   0.634    -5.941       0.1600      0.019705   \n",
       "3247          0.928   0.806    -7.621       0.0346      0.098034   \n",
       "\n",
       "       Instrumentalness  Liveness  Valence    Tempo  Duration_ms  \\\n",
       "4006           0.000175  0.116894    0.270   76.773    12.388382   \n",
       "3161           0.000038  0.064476    0.614  111.003    12.628506   \n",
       "8634           0.425268  0.056947    0.735  113.456    11.968076   \n",
       "7438           0.000005  0.226338    0.543  108.024    12.442519   \n",
       "2238           0.000004  0.431782    0.296  179.779    12.676814   \n",
       "...                 ...       ...      ...      ...          ...   \n",
       "13877          0.000000  0.549854    0.877  120.027    12.235636   \n",
       "9169           0.000001  0.078256    0.665  113.032    12.316352   \n",
       "11511          0.000002  0.122218    0.583   96.006    12.353751   \n",
       "4788           0.000030  0.254642    0.754  125.250    12.626453   \n",
       "3247           0.186480  0.076868    0.887  130.012    12.803557   \n",
       "\n",
       "       popularity_class  views_0_20  views_20_40  views_40_60  views_60_80  \\\n",
       "4006                  3           0            0            0            1   \n",
       "3161                  1           0            1            0            0   \n",
       "8634                  0           1            0            0            0   \n",
       "7438                  3           0            0            0            1   \n",
       "2238                  3           0            0            0            1   \n",
       "...                 ...         ...          ...          ...          ...   \n",
       "13877                 2           0            0            1            0   \n",
       "9169                  3           0            0            0            1   \n",
       "11511                 4           0            0            0            0   \n",
       "4788                  3           0            0            0            1   \n",
       "3247                  2           0            0            1            0   \n",
       "\n",
       "       views_80_100  \n",
       "4006              0  \n",
       "3161              0  \n",
       "8634              0  \n",
       "7438              0  \n",
       "2238              0  \n",
       "...             ...  \n",
       "13877             0  \n",
       "9169              0  \n",
       "11511             1  \n",
       "4788              0  \n",
       "3247              0  \n",
       "\n",
       "[14921 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.drop('Views', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd446d50-3b34-460a-8429-232be5b668e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "percentile_cols = ['views_0_20', 'views_20_40', 'views_40_60', 'views_60_80', 'views_80_100']\n",
    "cols_to_move = ['Views','popularity_class', 'views_0_20', 'views_20_40', 'views_40_60', 'views_60_80', 'views_80_100']\n",
    "\n",
    "X = df_model.drop(columns=cols_to_move)\n",
    "y_dict = {}  # słownik {nazwa_klasy: kolumna_etykiet}\n",
    "splits = {} # słownik podziałów na X_train, X_test, y_train, y_test dla każdej klasy\n",
    "\n",
    "for col in percentile_cols:\n",
    "    y = df_model[col]\n",
    "    y_dict[col] = y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y \n",
    "    )\n",
    "    \n",
    "    splits[col] = {\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4b84e4c-19ff-447f-be76-e31bb6babb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-8.261</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.281412</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.116894</td>\n",
       "      <td>0.270</td>\n",
       "      <td>76.773</td>\n",
       "      <td>12.388382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-11.325</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.314811</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.064476</td>\n",
       "      <td>0.614</td>\n",
       "      <td>111.003</td>\n",
       "      <td>12.628506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-6.767</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.425268</td>\n",
       "      <td>0.056947</td>\n",
       "      <td>0.735</td>\n",
       "      <td>113.456</td>\n",
       "      <td>11.968076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-3.599</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.268499</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.226338</td>\n",
       "      <td>0.543</td>\n",
       "      <td>108.024</td>\n",
       "      <td>12.442519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-9.136</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.439544</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.431782</td>\n",
       "      <td>0.296</td>\n",
       "      <td>179.779</td>\n",
       "      <td>12.676814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Danceability  Energy  Loudness  Speechiness  Acousticness  \\\n",
       "4006         0.517   0.428    -8.261       0.0267      0.281412   \n",
       "3161         0.652   0.440   -11.325       0.0271      0.314811   \n",
       "8634         0.835   0.835    -6.767       0.0973      0.015184   \n",
       "7438         0.529   0.894    -3.599       0.0412      0.268499   \n",
       "2238         0.393   0.290    -9.136       0.0385      0.439544   \n",
       "\n",
       "      Instrumentalness  Liveness  Valence    Tempo  Duration_ms  \n",
       "4006          0.000175  0.116894    0.270   76.773    12.388382  \n",
       "3161          0.000038  0.064476    0.614  111.003    12.628506  \n",
       "8634          0.425268  0.056947    0.735  113.456    11.968076  \n",
       "7438          0.000005  0.226338    0.543  108.024    12.442519  \n",
       "2238          0.000004  0.431782    0.296  179.779    12.676814  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90204a20-1def-4a81-a6c8-33850e0aa2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4006    0\n",
      "3161    0\n",
      "8634    1\n",
      "7438    0\n",
      "2238    0\n",
      "Name: views_0_20, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y_dict['views_0_20'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1da1a352-ff2f-4d7b-82bd-8e24446b9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testowanie modelu dla klasy: views_0_20 ===\n",
      "Seed 0: Accuracy = 0.7226\n",
      "Seed 5: Accuracy = 0.7296\n",
      "Seed 10: Accuracy = 0.7162\n",
      "Seed 15: Accuracy = 0.7167\n",
      "Seed 20: Accuracy = 0.7293\n",
      "Seed 25: Accuracy = 0.7124\n",
      "Seed 30: Accuracy = 0.7229\n",
      "Seed 35: Accuracy = 0.7221\n",
      "Seed 40: Accuracy = 0.7280\n",
      "Seed 45: Accuracy = 0.7328\n",
      "Seed 50: Accuracy = 0.7269\n",
      "Seed 55: Accuracy = 0.7172\n",
      "Seed 60: Accuracy = 0.7301\n",
      "Seed 65: Accuracy = 0.7266\n",
      "Seed 70: Accuracy = 0.7124\n",
      "Seed 75: Accuracy = 0.7202\n",
      "Seed 80: Accuracy = 0.7363\n",
      "Seed 85: Accuracy = 0.7221\n",
      "Seed 90: Accuracy = 0.7237\n",
      "Seed 95: Accuracy = 0.7194\n",
      "Seed 100: Accuracy = 0.7046\n",
      "\n",
      "Średnia dokładność dla views_0_20: 0.7225\n",
      "Odchylenie standardowe: 0.0074\n",
      "\n",
      "=== Testowanie modelu dla klasy: views_20_40 ===\n",
      "Seed 0: Accuracy = 0.7135\n",
      "Seed 5: Accuracy = 0.7129\n",
      "Seed 10: Accuracy = 0.7065\n",
      "Seed 15: Accuracy = 0.7156\n",
      "Seed 20: Accuracy = 0.7151\n",
      "Seed 25: Accuracy = 0.7076\n",
      "Seed 30: Accuracy = 0.7178\n",
      "Seed 35: Accuracy = 0.6990\n",
      "Seed 40: Accuracy = 0.7312\n",
      "Seed 45: Accuracy = 0.7151\n",
      "Seed 50: Accuracy = 0.7062\n",
      "Seed 55: Accuracy = 0.7081\n",
      "Seed 60: Accuracy = 0.7041\n",
      "Seed 65: Accuracy = 0.7020\n",
      "Seed 70: Accuracy = 0.6995\n",
      "Seed 75: Accuracy = 0.7140\n",
      "Seed 80: Accuracy = 0.7036\n",
      "Seed 85: Accuracy = 0.7062\n",
      "Seed 90: Accuracy = 0.7121\n",
      "Seed 95: Accuracy = 0.7172\n",
      "Seed 100: Accuracy = 0.7089\n",
      "\n",
      "Średnia dokładność dla views_20_40: 0.7103\n",
      "Odchylenie standardowe: 0.0073\n",
      "\n",
      "=== Testowanie modelu dla klasy: views_40_60 ===\n",
      "Seed 0: Accuracy = 0.7052\n",
      "Seed 5: Accuracy = 0.7044\n",
      "Seed 10: Accuracy = 0.7017\n",
      "Seed 15: Accuracy = 0.7054\n",
      "Seed 20: Accuracy = 0.7014\n",
      "Seed 25: Accuracy = 0.7095\n",
      "Seed 30: Accuracy = 0.7111\n",
      "Seed 35: Accuracy = 0.6923\n",
      "Seed 40: Accuracy = 0.7073\n",
      "Seed 45: Accuracy = 0.7103\n",
      "Seed 50: Accuracy = 0.7135\n",
      "Seed 55: Accuracy = 0.7006\n",
      "Seed 60: Accuracy = 0.7012\n",
      "Seed 65: Accuracy = 0.7097\n",
      "Seed 70: Accuracy = 0.7052\n",
      "Seed 75: Accuracy = 0.7089\n",
      "Seed 80: Accuracy = 0.7014\n",
      "Seed 85: Accuracy = 0.7065\n",
      "Seed 90: Accuracy = 0.7148\n",
      "Seed 95: Accuracy = 0.6875\n",
      "Seed 100: Accuracy = 0.7062\n",
      "\n",
      "Średnia dokładność dla views_40_60: 0.7050\n",
      "Odchylenie standardowe: 0.0063\n",
      "\n",
      "=== Testowanie modelu dla klasy: views_60_80 ===\n",
      "Seed 0: Accuracy = 0.7076\n",
      "Seed 5: Accuracy = 0.7146\n",
      "Seed 10: Accuracy = 0.7180\n",
      "Seed 15: Accuracy = 0.6950\n",
      "Seed 20: Accuracy = 0.7057\n",
      "Seed 25: Accuracy = 0.7038\n",
      "Seed 30: Accuracy = 0.7065\n",
      "Seed 35: Accuracy = 0.7030\n",
      "Seed 40: Accuracy = 0.7089\n",
      "Seed 45: Accuracy = 0.7068\n",
      "Seed 50: Accuracy = 0.7012\n",
      "Seed 55: Accuracy = 0.7079\n",
      "Seed 60: Accuracy = 0.7046\n",
      "Seed 65: Accuracy = 0.7111\n",
      "Seed 70: Accuracy = 0.7070\n",
      "Seed 75: Accuracy = 0.6995\n",
      "Seed 80: Accuracy = 0.7025\n",
      "Seed 85: Accuracy = 0.7143\n",
      "Seed 90: Accuracy = 0.7044\n",
      "Seed 95: Accuracy = 0.7062\n",
      "Seed 100: Accuracy = 0.7012\n",
      "\n",
      "Średnia dokładność dla views_60_80: 0.7062\n",
      "Odchylenie standardowe: 0.0052\n",
      "\n",
      "=== Testowanie modelu dla klasy: views_80_100 ===\n",
      "Seed 0: Accuracy = 0.7221\n",
      "Seed 5: Accuracy = 0.7255\n",
      "Seed 10: Accuracy = 0.7237\n",
      "Seed 15: Accuracy = 0.7357\n",
      "Seed 20: Accuracy = 0.7121\n",
      "Seed 25: Accuracy = 0.7355\n",
      "Seed 30: Accuracy = 0.7373\n",
      "Seed 35: Accuracy = 0.7245\n",
      "Seed 40: Accuracy = 0.7408\n",
      "Seed 45: Accuracy = 0.7384\n",
      "Seed 50: Accuracy = 0.7247\n",
      "Seed 55: Accuracy = 0.7202\n",
      "Seed 60: Accuracy = 0.7312\n",
      "Seed 65: Accuracy = 0.7360\n",
      "Seed 70: Accuracy = 0.7196\n",
      "Seed 75: Accuracy = 0.7255\n",
      "Seed 80: Accuracy = 0.7424\n",
      "Seed 85: Accuracy = 0.7269\n",
      "Seed 90: Accuracy = 0.7320\n",
      "Seed 95: Accuracy = 0.7438\n",
      "Seed 100: Accuracy = 0.7344\n",
      "\n",
      "Średnia dokładność dla views_80_100: 0.7301\n",
      "Odchylenie standardowe: 0.0083\n",
      "\n",
      "=== Podsumowanie wszystkich percentyli ===\n",
      "views_0_20: Średnia = 0.7225, STD = 0.0074\n",
      "views_20_40: Średnia = 0.7103, STD = 0.0073\n",
      "views_40_60: Średnia = 0.7050, STD = 0.0063\n",
      "views_60_80: Średnia = 0.7062, STD = 0.0052\n",
      "views_80_100: Średnia = 0.7301, STD = 0.0083\n"
     ]
    }
   ],
   "source": [
    "# DECISION TREE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for col in percentile_cols:\n",
    "    print(f\"\\n=== Testowanie modelu dla klasy: {col} ===\")\n",
    "    accuracies = []\n",
    "    \n",
    "\n",
    "    for seed in range(0, 101, 5):\n",
    "        \n",
    "        X_train = splits[col]['X_train']\n",
    "        X_test = splits[col]['X_test']\n",
    "        y_train = splits[col]['y_train']\n",
    "        y_test = splits[col]['y_test']\n",
    "        \n",
    "        model = DecisionTreeClassifier(random_state=80)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "    \n",
    "    mean_acc = np.mean(accuracies)\n",
    "    std_acc = np.std(accuracies)\n",
    "    results[col] = (mean_acc, std_acc)\n",
    "\n",
    "    print(f\"\\nŚrednia dokładność dla {col}: {mean_acc:.4f}\")\n",
    "    print(f\"Odchylenie standardowe: {std_acc:.4f}\")\n",
    "\n",
    "print(\"\\n=== Podsumowanie wszystkich percentyli ===\")\n",
    "for col, (mean_acc, std_acc) in results.items():\n",
    "    print(f\"{col}: Średnia = {mean_acc:.4f}, STD = {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7c69060-3c15-47c6-abcf-701cf646c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testowanie modelu Random Forest dla klasy: views_0_20 ===\n",
      "Seed 0: Accuracy = 0.8141\n",
      "Seed 10: Accuracy = 0.8141\n",
      "Seed 20: Accuracy = 0.8141\n",
      "Seed 30: Accuracy = 0.8141\n",
      "Seed 40: Accuracy = 0.8141\n",
      "Seed 50: Accuracy = 0.8141\n",
      "Seed 60: Accuracy = 0.8141\n",
      "Seed 70: Accuracy = 0.8141\n",
      "Seed 80: Accuracy = 0.8141\n",
      "Seed 90: Accuracy = 0.8141\n",
      "Seed 100: Accuracy = 0.8141\n",
      "\n",
      "Średnia dokładność dla views_0_20: 0.8141\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu Random Forest dla klasy: views_20_40 ===\n",
      "Seed 0: Accuracy = 0.8184\n",
      "Seed 10: Accuracy = 0.8184\n",
      "Seed 20: Accuracy = 0.8184\n",
      "Seed 30: Accuracy = 0.8184\n",
      "Seed 40: Accuracy = 0.8184\n",
      "Seed 50: Accuracy = 0.8184\n",
      "Seed 60: Accuracy = 0.8184\n",
      "Seed 70: Accuracy = 0.8184\n",
      "Seed 80: Accuracy = 0.8184\n",
      "Seed 90: Accuracy = 0.8184\n",
      "Seed 100: Accuracy = 0.8184\n",
      "\n",
      "Średnia dokładność dla views_20_40: 0.8184\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu Random Forest dla klasy: views_40_60 ===\n",
      "Seed 0: Accuracy = 0.8134\n",
      "Seed 10: Accuracy = 0.8134\n",
      "Seed 20: Accuracy = 0.8134\n",
      "Seed 30: Accuracy = 0.8134\n",
      "Seed 40: Accuracy = 0.8134\n",
      "Seed 50: Accuracy = 0.8134\n",
      "Seed 60: Accuracy = 0.8134\n",
      "Seed 70: Accuracy = 0.8134\n",
      "Seed 80: Accuracy = 0.8134\n",
      "Seed 90: Accuracy = 0.8134\n",
      "Seed 100: Accuracy = 0.8134\n",
      "\n",
      "Średnia dokładność dla views_40_60: 0.8134\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu Random Forest dla klasy: views_60_80 ===\n",
      "Seed 0: Accuracy = 0.8188\n",
      "Seed 10: Accuracy = 0.8188\n",
      "Seed 20: Accuracy = 0.8188\n",
      "Seed 30: Accuracy = 0.8188\n",
      "Seed 40: Accuracy = 0.8188\n",
      "Seed 50: Accuracy = 0.8188\n",
      "Seed 60: Accuracy = 0.8188\n",
      "Seed 70: Accuracy = 0.8188\n",
      "Seed 80: Accuracy = 0.8188\n",
      "Seed 90: Accuracy = 0.8188\n",
      "Seed 100: Accuracy = 0.8188\n",
      "\n",
      "Średnia dokładność dla views_60_80: 0.8188\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu Random Forest dla klasy: views_80_100 ===\n",
      "Seed 0: Accuracy = 0.8271\n",
      "Seed 10: Accuracy = 0.8271\n",
      "Seed 20: Accuracy = 0.8271\n",
      "Seed 30: Accuracy = 0.8271\n",
      "Seed 40: Accuracy = 0.8271\n",
      "Seed 50: Accuracy = 0.8271\n",
      "Seed 60: Accuracy = 0.8271\n",
      "Seed 70: Accuracy = 0.8271\n",
      "Seed 80: Accuracy = 0.8271\n",
      "Seed 90: Accuracy = 0.8271\n",
      "Seed 100: Accuracy = 0.8271\n",
      "\n",
      "Średnia dokładność dla views_80_100: 0.8271\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Podsumowanie wszystkich percentyli (Random Forest) ===\n",
      "views_0_20: Średnia = 0.8141, STD = 0.0000\n",
      "views_20_40: Średnia = 0.8184, STD = 0.0000\n",
      "views_40_60: Średnia = 0.8134, STD = 0.0000\n",
      "views_60_80: Średnia = 0.8188, STD = 0.0000\n",
      "views_80_100: Średnia = 0.8271, STD = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "results_rf = {}\n",
    "\n",
    "for col in percentile_cols:\n",
    "    print(f\"\\n=== Testowanie modelu Random Forest dla klasy: {col} ===\")\n",
    "    accuracies = []\n",
    "    \n",
    "\n",
    "    for seed in range(0, 101, 10):\n",
    "        X_train = splits[col]['X_train']\n",
    "        X_test = splits[col]['X_test']\n",
    "        y_train = splits[col]['y_train']\n",
    "        y_test = splits[col]['y_test']\n",
    "        \n",
    "        model = RandomForestClassifier(random_state=80, n_estimators=100)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        print(f\"Seed {seed}: Accuracy = {acc:.4f}\")\n",
    "    \n",
    "    mean_acc = np.mean(accuracies)\n",
    "    std_acc = np.std(accuracies)\n",
    "    results_rf[col] = (mean_acc, std_acc)\n",
    "\n",
    "    print(f\"\\nŚrednia dokładność dla {col}: {mean_acc:.4f}\")\n",
    "    print(f\"Odchylenie standardowe: {std_acc:.4f}\")\n",
    "\n",
    "print(\"\\n=== Podsumowanie wszystkich percentyli (Random Forest) ===\")\n",
    "for col, (mean_acc, std_acc) in results_rf.items():\n",
    "    print(f\"{col}: Średnia = {mean_acc:.4f}, STD = {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac556ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Szukanie hiperparametrów dla klasy: views_0_20 ===\n",
      "Najlepsze parametry: {'n_estimators': 50, 'min_samples_split': 5, 'max_features': 'sqrt', 'max_depth': 50}\n",
      "Accuracy dla views_0_20: 0.8161\n",
      "\n",
      "=== Szukanie hiperparametrów dla klasy: views_20_40 ===\n",
      "Najlepsze parametry: {'n_estimators': 50, 'min_samples_split': 5, 'max_features': 'sqrt', 'max_depth': 50}\n",
      "Accuracy dla views_20_40: 0.8171\n",
      "\n",
      "=== Szukanie hiperparametrów dla klasy: views_40_60 ===\n",
      "Najlepsze parametry: {'n_estimators': 50, 'min_samples_split': 5, 'max_features': 'sqrt', 'max_depth': 50}\n",
      "Accuracy dla views_40_60: 0.8121\n",
      "\n",
      "=== Szukanie hiperparametrów dla klasy: views_60_80 ===\n",
      "Najlepsze parametry: {'n_estimators': 50, 'min_samples_split': 5, 'max_features': 'sqrt', 'max_depth': 50}\n",
      "Accuracy dla views_60_80: 0.8171\n",
      "\n",
      "=== Szukanie hiperparametrów dla klasy: views_80_100 ===\n",
      "Najlepsze parametry: {'n_estimators': 200, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "Accuracy dla views_80_100: 0.8255\n"
     ]
    }
   ],
   "source": [
    "# optymalizacja hiperparametrow dla RF\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "percentile_cols = ['views_0_20', 'views_20_40', 'views_40_60', 'views_60_80', 'views_80_100']\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "results_rf = {}\n",
    "\n",
    "for col in percentile_cols:\n",
    "    print(f\"\\n=== Szukanie hiperparametrów dla klasy: {col} ===\")\n",
    "    \n",
    "    X_train = splits[col]['X_train']\n",
    "    X_test = splits[col]['X_test']\n",
    "    y_train = splits[col]['y_train']\n",
    "    y_test = splits[col]['y_test']\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=80)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='accuracy',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results_rf[col] = {\n",
    "        \"best_params\": random_search.best_params_,\n",
    "        \"accuracy\": acc\n",
    "    }\n",
    "\n",
    "    print(f\"Najlepsze parametry: {random_search.best_params_}\")\n",
    "    print(f\"Accuracy dla {col}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dc9b561-0951-40f0-8088-1a6ad43d4f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testowanie modelu XGBoost dla klasy: views_0_20 ===\n",
      "Accuracy = 0.7980\n",
      "\n",
      "Średnia dokładność dla views_0_20: 0.7980\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu XGBoost dla klasy: views_20_40 ===\n",
      "Accuracy = 0.7943\n",
      "\n",
      "Średnia dokładność dla views_20_40: 0.7943\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu XGBoost dla klasy: views_40_60 ===\n",
      "Accuracy = 0.7910\n",
      "\n",
      "Średnia dokładność dla views_40_60: 0.7910\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu XGBoost dla klasy: views_60_80 ===\n",
      "Accuracy = 0.7923\n",
      "\n",
      "Średnia dokładność dla views_60_80: 0.7923\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Testowanie modelu XGBoost dla klasy: views_80_100 ===\n",
      "Accuracy = 0.8003\n",
      "\n",
      "Średnia dokładność dla views_80_100: 0.8003\n",
      "Odchylenie standardowe: 0.0000\n",
      "\n",
      "=== Podsumowanie wszystkich percentyli (XGBoost) ===\n",
      "views_0_20: Średnia = 0.7980, STD = 0.0000\n",
      "views_20_40: Średnia = 0.7943, STD = 0.0000\n",
      "views_40_60: Średnia = 0.7910, STD = 0.0000\n",
      "views_60_80: Średnia = 0.7923, STD = 0.0000\n",
      "views_80_100: Średnia = 0.8003, STD = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# XGB  - WYBRANY MODEL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "results_xgb = {}\n",
    "\n",
    "for col in percentile_cols:\n",
    "    print(f\"\\n=== Testowanie modelu XGBoost dla klasy: {col} ===\")\n",
    "    accuracies = []\n",
    "    \n",
    "\n",
    "    X_train = splits[col]['X_train']\n",
    "    X_test = splits[col]['X_test']\n",
    "    y_train = splits[col]['y_train']\n",
    "    y_test = splits[col]['y_test']\n",
    "\n",
    "    model = XGBClassifier(eval_metric='logloss', random_state=80)\n",
    "    model.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Accuracy = {acc:.4f}\")\n",
    "    \n",
    "    mean_acc = np.mean(accuracies)\n",
    "    std_acc = np.std(accuracies)\n",
    "    results_xgb[col] = (mean_acc, std_acc)\n",
    "\n",
    "    print(f\"\\nŚrednia dokładność dla {col}: {mean_acc:.4f}\")\n",
    "    print(f\"Odchylenie standardowe: {std_acc:.4f}\")\n",
    "\n",
    "print(\"\\n=== Podsumowanie wszystkich percentyli (XGBoost) ===\")\n",
    "for col, (mean_acc, std_acc) in results_xgb.items():\n",
    "    print(f\"{col}: Średnia = {mean_acc:.4f}, STD = {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d496fadb-eec8-4b6e-8f34-0c00a7518a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:28,066] A new study created in memory with name: no-name-a5d77214-d8b3-42d2-a5b0-f75656f09cb8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hiperparametry dla klasy: views_0_20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:28,668] Trial 0 finished with value: 0.36096718480138174 and parameters: {'n_estimators': 97, 'max_depth': 8, 'learning_rate': 0.16157105115908865, 'subsample': 0.6110798681290417, 'colsample_bytree': 0.7222208418997299}. Best is trial 0 with value: 0.36096718480138174.\n",
      "[I 2025-04-22 23:08:28,855] Trial 1 finished with value: 0.36992681304058544 and parameters: {'n_estimators': 88, 'max_depth': 4, 'learning_rate': 0.2813865749434559, 'subsample': 0.8761105156036327, 'colsample_bytree': 0.9467941686210843}. Best is trial 1 with value: 0.36992681304058544.\n",
      "[I 2025-04-22 23:08:29,335] Trial 2 finished with value: 0.3087248322147651 and parameters: {'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.22913736451207506, 'subsample': 0.8466781557765766, 'colsample_bytree': 0.7656609731941735}. Best is trial 1 with value: 0.36992681304058544.\n",
      "[I 2025-04-22 23:08:29,453] Trial 3 finished with value: 0.396887159533074 and parameters: {'n_estimators': 163, 'max_depth': 4, 'learning_rate': 0.11077287162000023, 'subsample': 0.6012369329529362, 'colsample_bytree': 0.5296615084042392}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:29,599] Trial 4 finished with value: 0.3951149425287356 and parameters: {'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.05643691080549858, 'subsample': 0.6182638170754478, 'colsample_bytree': 0.9851891772097168}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:29,699] Trial 5 finished with value: 0.3878787878787879 and parameters: {'n_estimators': 89, 'max_depth': 5, 'learning_rate': 0.09972742187399615, 'subsample': 0.5617335017600067, 'colsample_bytree': 0.9573383135724776}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:29,838] Trial 6 finished with value: 0.3905489923558026 and parameters: {'n_estimators': 155, 'max_depth': 5, 'learning_rate': 0.09369993595848408, 'subsample': 0.9562624234626214, 'colsample_bytree': 0.5514979708846017}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:29,991] Trial 7 finished with value: 0.33828382838283827 and parameters: {'n_estimators': 89, 'max_depth': 7, 'learning_rate': 0.2800942345785143, 'subsample': 0.5016120675443176, 'colsample_bytree': 0.915154640882361}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:30,098] Trial 8 finished with value: 0.3930942895086321 and parameters: {'n_estimators': 111, 'max_depth': 5, 'learning_rate': 0.04886596407924227, 'subsample': 0.5504615891955493, 'colsample_bytree': 0.710664751804509}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:30,235] Trial 9 finished with value: 0.3604826546003016 and parameters: {'n_estimators': 65, 'max_depth': 7, 'learning_rate': 0.15743073087574308, 'subsample': 0.5681864410073028, 'colsample_bytree': 0.802718307346123}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:30,425] Trial 10 finished with value: 0.3759398496240602 and parameters: {'n_estimators': 194, 'max_depth': 3, 'learning_rate': 0.19408762964835735, 'subsample': 0.7097662588375858, 'colsample_bytree': 0.5044933248823928}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:30,588] Trial 11 finished with value: 0.39182058047493407 and parameters: {'n_estimators': 155, 'max_depth': 3, 'learning_rate': 0.010471519514161032, 'subsample': 0.6818059655716913, 'colsample_bytree': 0.6177093708137529}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:30,862] Trial 12 finished with value: 0.37398373983739835 and parameters: {'n_estimators': 151, 'max_depth': 6, 'learning_rate': 0.0951715785493168, 'subsample': 0.6468129112995307, 'colsample_bytree': 0.8539316746427051}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:31,503] Trial 13 finished with value: 0.36275460717749763 and parameters: {'n_estimators': 188, 'max_depth': 9, 'learning_rate': 0.049262659794366156, 'subsample': 0.8156085565429217, 'colsample_bytree': 0.6466116129440598}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:31,759] Trial 14 finished with value: 0.3650920736589271 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.11758609525926061, 'subsample': 0.7580813374918841, 'colsample_bytree': 0.9941347210506818}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:31,960] Trial 15 finished with value: 0.3948553054662379 and parameters: {'n_estimators': 175, 'max_depth': 4, 'learning_rate': 0.05130690636674057, 'subsample': 0.7593305040236291, 'colsample_bytree': 0.8448973893988535}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:32,045] Trial 16 finished with value: 0.3681847338037203 and parameters: {'n_estimators': 52, 'max_depth': 4, 'learning_rate': 0.1343081404968543, 'subsample': 0.6357029630748402, 'colsample_bytree': 0.646883154734946}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:32,349] Trial 17 finished with value: 0.37190082644628103 and parameters: {'n_estimators': 134, 'max_depth': 8, 'learning_rate': 0.019859433078725036, 'subsample': 0.6908529340985117, 'colsample_bytree': 0.5950185309148256}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:32,582] Trial 18 finished with value: 0.38661710037174724 and parameters: {'n_estimators': 172, 'max_depth': 6, 'learning_rate': 0.06859126303501836, 'subsample': 0.5987254544550202, 'colsample_bytree': 0.879243295878377}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:32,701] Trial 19 finished with value: 0.36853002070393376 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.19179726182834908, 'subsample': 0.505331268489103, 'colsample_bytree': 0.5041218310848934}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:32,808] Trial 20 finished with value: 0.38466373350094285 and parameters: {'n_estimators': 129, 'max_depth': 3, 'learning_rate': 0.07434742133594537, 'subsample': 0.9995173354908065, 'colsample_bytree': 0.6840041750309481}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:32,957] Trial 21 finished with value: 0.3899289864428664 and parameters: {'n_estimators': 176, 'max_depth': 4, 'learning_rate': 0.04596828291569617, 'subsample': 0.7635803590117898, 'colsample_bytree': 0.8361231167339649}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:33,106] Trial 22 finished with value: 0.38557377049180325 and parameters: {'n_estimators': 172, 'max_depth': 4, 'learning_rate': 0.1305487139422833, 'subsample': 0.7229974560607926, 'colsample_bytree': 0.7907989266694444}. Best is trial 3 with value: 0.396887159533074.\n",
      "[I 2025-04-22 23:08:33,268] Trial 23 finished with value: 0.4028589993502274 and parameters: {'n_estimators': 198, 'max_depth': 4, 'learning_rate': 0.03317687078146252, 'subsample': 0.7929167914981928, 'colsample_bytree': 0.8911686125271476}. Best is trial 23 with value: 0.4028589993502274.\n",
      "[I 2025-04-22 23:08:33,477] Trial 24 finished with value: 0.3959866220735786 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.02803755096181522, 'subsample': 0.8042756268912218, 'colsample_bytree': 0.9049670770358501}. Best is trial 23 with value: 0.4028589993502274.\n",
      "[I 2025-04-22 23:08:33,742] Trial 25 finished with value: 0.389945652173913 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.02900419787078312, 'subsample': 0.8068341775736565, 'colsample_bytree': 0.8991188261185896}. Best is trial 23 with value: 0.4028589993502274.\n",
      "[I 2025-04-22 23:08:33,915] Trial 26 finished with value: 0.3836838750796686 and parameters: {'n_estimators': 184, 'max_depth': 3, 'learning_rate': 0.08018703580323376, 'subsample': 0.9113726022227868, 'colsample_bytree': 0.9448302734449725}. Best is trial 23 with value: 0.4028589993502274.\n",
      "[I 2025-04-22 23:08:34,095] Trial 27 finished with value: 0.3942931258106355 and parameters: {'n_estimators': 164, 'max_depth': 4, 'learning_rate': 0.03682510850227898, 'subsample': 0.8028861575597042, 'colsample_bytree': 0.761902444514174}. Best is trial 23 with value: 0.4028589993502274.\n",
      "[I 2025-04-22 23:08:34,342] Trial 28 finished with value: 0.39486139283299526 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.010729181783940455, 'subsample': 0.8622000622882805, 'colsample_bytree': 0.8128701497569443}. Best is trial 23 with value: 0.4028589993502274.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:34,511] Trial 29 finished with value: 0.38834951456310685 and parameters: {'n_estimators': 199, 'max_depth': 3, 'learning_rate': 0.1735288809629894, 'subsample': 0.9005157120294628, 'colsample_bytree': 0.7261744850416946}. Best is trial 23 with value: 0.4028589993502274.\n",
      "[I 2025-04-22 23:08:34,725] A new study created in memory with name: no-name-7e860c81-fca0-4e71-8643-60dda52185d1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_0_20: {'n_estimators': 198, 'max_depth': 4, 'learning_rate': 0.03317687078146252, 'subsample': 0.7929167914981928, 'colsample_bytree': 0.8911686125271476, 'scale_pos_weight': 3.9983249581239533}\n",
      "Accuracy:  0.6921\n",
      "Precision: 0.3291\n",
      "Recall:    0.5193\n",
      "F1-score:  0.4029\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.74      0.79      2388\n",
      "           1       0.33      0.52      0.40       597\n",
      "\n",
      "    accuracy                           0.69      2985\n",
      "   macro avg       0.59      0.63      0.60      2985\n",
      "weighted avg       0.75      0.69      0.71      2985\n",
      "\n",
      "\n",
      "=== Hiperparametry dla klasy: views_20_40 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:35,023] Trial 0 finished with value: 0.291044776119403 and parameters: {'n_estimators': 125, 'max_depth': 8, 'learning_rate': 0.19419596794291677, 'subsample': 0.6352297230235371, 'colsample_bytree': 0.7588461557798527}. Best is trial 0 with value: 0.291044776119403.\n",
      "[I 2025-04-22 23:08:35,085] Trial 1 finished with value: 0.31668558456299656 and parameters: {'n_estimators': 107, 'max_depth': 3, 'learning_rate': 0.18214422160878144, 'subsample': 0.9605330026700831, 'colsample_bytree': 0.8696943745562989}. Best is trial 1 with value: 0.31668558456299656.\n",
      "[I 2025-04-22 23:08:35,306] Trial 2 finished with value: 0.3037475345167653 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.18013266569714034, 'subsample': 0.6762335348843751, 'colsample_bytree': 0.6416100463135532}. Best is trial 1 with value: 0.31668558456299656.\n",
      "[I 2025-04-22 23:08:35,433] Trial 3 finished with value: 0.30048916841369677 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.049461550946429254, 'subsample': 0.6614968035439543, 'colsample_bytree': 0.5923288774307032}. Best is trial 1 with value: 0.31668558456299656.\n",
      "[I 2025-04-22 23:08:35,525] Trial 4 finished with value: 0.30891950688905 and parameters: {'n_estimators': 98, 'max_depth': 6, 'learning_rate': 0.13562458352869988, 'subsample': 0.951034272871292, 'colsample_bytree': 0.5753708251828484}. Best is trial 1 with value: 0.31668558456299656.\n",
      "[I 2025-04-22 23:08:35,827] Trial 5 finished with value: 0.2662337662337662 and parameters: {'n_estimators': 145, 'max_depth': 9, 'learning_rate': 0.2843378454651243, 'subsample': 0.8772492433008964, 'colsample_bytree': 0.8201015047913509}. Best is trial 1 with value: 0.31668558456299656.\n",
      "[I 2025-04-22 23:08:36,172] Trial 6 finished with value: 0.28361344537815125 and parameters: {'n_estimators': 177, 'max_depth': 8, 'learning_rate': 0.1544693678718062, 'subsample': 0.9076351522159444, 'colsample_bytree': 0.8643477200110019}. Best is trial 1 with value: 0.31668558456299656.\n",
      "[I 2025-04-22 23:08:36,551] Trial 7 finished with value: 0.27370689655172414 and parameters: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.25448592593106084, 'subsample': 0.9046589101175299, 'colsample_bytree': 0.7909720809034988}. Best is trial 1 with value: 0.31668558456299656.\n",
      "[I 2025-04-22 23:08:36,715] Trial 8 finished with value: 0.327217125382263 and parameters: {'n_estimators': 145, 'max_depth': 6, 'learning_rate': 0.23785540352864754, 'subsample': 0.5162858743334182, 'colsample_bytree': 0.626665622570818}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:37,344] Trial 9 finished with value: 0.2679738562091503 and parameters: {'n_estimators': 189, 'max_depth': 9, 'learning_rate': 0.1319677322067834, 'subsample': 0.6596701427611784, 'colsample_bytree': 0.9701204400575236}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:37,468] Trial 10 finished with value: 0.3127906976744186 and parameters: {'n_estimators': 66, 'max_depth': 4, 'learning_rate': 0.014057778866727821, 'subsample': 0.5082996959685832, 'colsample_bytree': 0.6817607051044157}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:37,601] Trial 11 finished with value: 0.31797235023041476 and parameters: {'n_estimators': 102, 'max_depth': 3, 'learning_rate': 0.22962507475511257, 'subsample': 0.771387603831617, 'colsample_bytree': 0.5068350809117588}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:37,719] Trial 12 finished with value: 0.2922318125770654 and parameters: {'n_estimators': 73, 'max_depth': 4, 'learning_rate': 0.2421481774938787, 'subsample': 0.7947849976485646, 'colsample_bytree': 0.5035995224974197}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:37,892] Trial 13 finished with value: 0.3001293661060802 and parameters: {'n_estimators': 94, 'max_depth': 5, 'learning_rate': 0.22425255954531287, 'subsample': 0.5139344916569417, 'colsample_bytree': 0.5175078867555711}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:38,045] Trial 14 finished with value: 0.3186360964138742 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.28829529233420403, 'subsample': 0.7822232021679716, 'colsample_bytree': 0.6831778882850019}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:38,315] Trial 15 finished with value: 0.31187410586552217 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.29932090867934713, 'subsample': 0.5905603531477476, 'colsample_bytree': 0.7019337873156113}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:38,769] Trial 16 finished with value: 0.3010948905109489 and parameters: {'n_estimators': 120, 'max_depth': 7, 'learning_rate': 0.27298028390845447, 'subsample': 0.8267778402304549, 'colsample_bytree': 0.6272585175407402}. Best is trial 8 with value: 0.327217125382263.\n",
      "[I 2025-04-22 23:08:39,086] Trial 17 finished with value: 0.32764505119453924 and parameters: {'n_estimators': 160, 'max_depth': 5, 'learning_rate': 0.08657582157191754, 'subsample': 0.7336754659978932, 'colsample_bytree': 0.7064510642114379}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:39,404] Trial 18 finished with value: 0.29711141678129294 and parameters: {'n_estimators': 162, 'max_depth': 5, 'learning_rate': 0.09551365229839959, 'subsample': 0.7162014812336792, 'colsample_bytree': 0.7283803675022963}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:39,750] Trial 19 finished with value: 0.292118582791034 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.06914043153200294, 'subsample': 0.5806468868097143, 'colsample_bytree': 0.5823431381544968}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:40,070] Trial 20 finished with value: 0.2927272727272727 and parameters: {'n_estimators': 50, 'max_depth': 10, 'learning_rate': 0.09744329874885946, 'subsample': 0.7154405653736751, 'colsample_bytree': 0.6469761803165613}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:40,271] Trial 21 finished with value: 0.31483870967741934 and parameters: {'n_estimators': 131, 'max_depth': 4, 'learning_rate': 0.20967551975844723, 'subsample': 0.8315454603070634, 'colsample_bytree': 0.6816862350666382}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:40,476] Trial 22 finished with value: 0.3198090692124105 and parameters: {'n_estimators': 159, 'max_depth': 3, 'learning_rate': 0.2620250718470789, 'subsample': 0.7373066386973577, 'colsample_bytree': 0.7344426487486996}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:40,782] Trial 23 finished with value: 0.28744326777609686 and parameters: {'n_estimators': 159, 'max_depth': 5, 'learning_rate': 0.25731895526834503, 'subsample': 0.7312360111972867, 'colsample_bytree': 0.7468371340633462}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:40,992] Trial 24 finished with value: 0.31975308641975314 and parameters: {'n_estimators': 156, 'max_depth': 4, 'learning_rate': 0.12348576812266839, 'subsample': 0.5964365675146894, 'colsample_bytree': 0.8093144624976268}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:41,482] Trial 25 finished with value: 0.3060921248142645 and parameters: {'n_estimators': 178, 'max_depth': 7, 'learning_rate': 0.017133916075269512, 'subsample': 0.5442680327877921, 'colsample_bytree': 0.7230326678135732}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:41,878] Trial 26 finished with value: 0.31164658634538156 and parameters: {'n_estimators': 171, 'max_depth': 6, 'learning_rate': 0.1576432062775661, 'subsample': 0.6294875647390576, 'colsample_bytree': 0.780290228741847}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:42,190] Trial 27 finished with value: 0.29314420803782504 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.26443427983294315, 'subsample': 0.8283794351463649, 'colsample_bytree': 0.8539974999911893}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:42,443] Trial 28 finished with value: 0.31560490940970193 and parameters: {'n_estimators': 137, 'max_depth': 3, 'learning_rate': 0.21208088400543607, 'subsample': 0.7498835652400184, 'colsample_bytree': 0.9263593216368375}. Best is trial 17 with value: 0.32764505119453924.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:42,818] Trial 29 finished with value: 0.2928709055876686 and parameters: {'n_estimators': 113, 'max_depth': 8, 'learning_rate': 0.19055758890234173, 'subsample': 0.9938778151053658, 'colsample_bytree': 0.7638710165732712}. Best is trial 17 with value: 0.32764505119453924.\n",
      "[I 2025-04-22 23:08:43,168] A new study created in memory with name: no-name-6ad88b42-0182-423d-9ef5-c50c5dc776c8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_20_40: {'n_estimators': 160, 'max_depth': 5, 'learning_rate': 0.08657582157191754, 'subsample': 0.7336754659978932, 'colsample_bytree': 0.7064510642114379, 'scale_pos_weight': 4.000418935902807}\n",
      "Accuracy:  0.6700\n",
      "Precision: 0.2765\n",
      "Recall:    0.4020\n",
      "F1-score:  0.3276\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78      2388\n",
      "           1       0.28      0.40      0.33       597\n",
      "\n",
      "    accuracy                           0.67      2985\n",
      "   macro avg       0.55      0.57      0.55      2985\n",
      "weighted avg       0.72      0.67      0.69      2985\n",
      "\n",
      "\n",
      "=== Hiperparametry dla klasy: views_40_60 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:43,911] Trial 0 finished with value: 0.22073578595317728 and parameters: {'n_estimators': 199, 'max_depth': 9, 'learning_rate': 0.12019980448845832, 'subsample': 0.7757075133299707, 'colsample_bytree': 0.5010264509338189}. Best is trial 0 with value: 0.22073578595317728.\n",
      "[I 2025-04-22 23:08:44,305] Trial 1 finished with value: 0.2743682310469314 and parameters: {'n_estimators': 189, 'max_depth': 6, 'learning_rate': 0.28322777147775213, 'subsample': 0.8105325271492213, 'colsample_bytree': 0.9093100969463538}. Best is trial 1 with value: 0.2743682310469314.\n",
      "[I 2025-04-22 23:08:44,583] Trial 2 finished with value: 0.271244635193133 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.0763672013872222, 'subsample': 0.5171877735041874, 'colsample_bytree': 0.776004234840738}. Best is trial 1 with value: 0.2743682310469314.\n",
      "[I 2025-04-22 23:08:44,877] Trial 3 finished with value: 0.28977272727272724 and parameters: {'n_estimators': 163, 'max_depth': 6, 'learning_rate': 0.06271083681230832, 'subsample': 0.9247836313237798, 'colsample_bytree': 0.8527144753918692}. Best is trial 3 with value: 0.28977272727272724.\n",
      "[I 2025-04-22 23:08:45,045] Trial 4 finished with value: 0.30216718266253867 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.09424288313444203, 'subsample': 0.9432532537228011, 'colsample_bytree': 0.6410316108447897}. Best is trial 4 with value: 0.30216718266253867.\n",
      "[I 2025-04-22 23:08:45,313] Trial 5 finished with value: 0.2857142857142857 and parameters: {'n_estimators': 152, 'max_depth': 6, 'learning_rate': 0.15634144519441107, 'subsample': 0.8649677574235415, 'colsample_bytree': 0.5991399827606984}. Best is trial 4 with value: 0.30216718266253867.\n",
      "[I 2025-04-22 23:08:45,450] Trial 6 finished with value: 0.33049946865037194 and parameters: {'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.015369585971063606, 'subsample': 0.8365427753235932, 'colsample_bytree': 0.6833210022510439}. Best is trial 6 with value: 0.33049946865037194.\n",
      "[I 2025-04-22 23:08:45,624] Trial 7 finished with value: 0.2972972972972973 and parameters: {'n_estimators': 156, 'max_depth': 3, 'learning_rate': 0.22583502864208274, 'subsample': 0.5896054458427213, 'colsample_bytree': 0.7358143127693454}. Best is trial 6 with value: 0.33049946865037194.\n",
      "[I 2025-04-22 23:08:45,968] Trial 8 finished with value: 0.27484874675885906 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.1555295157721306, 'subsample': 0.8867171598074259, 'colsample_bytree': 0.7027566715906932}. Best is trial 6 with value: 0.33049946865037194.\n",
      "[I 2025-04-22 23:08:46,574] Trial 9 finished with value: 0.24191866527632952 and parameters: {'n_estimators': 176, 'max_depth': 8, 'learning_rate': 0.19655818851603213, 'subsample': 0.7280325306589158, 'colsample_bytree': 0.5210251864527069}. Best is trial 6 with value: 0.33049946865037194.\n",
      "[I 2025-04-22 23:08:46,765] Trial 10 finished with value: 0.3338469440164355 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.014762163614670726, 'subsample': 0.6757239867444571, 'colsample_bytree': 0.8185454368212413}. Best is trial 10 with value: 0.3338469440164355.\n",
      "[I 2025-04-22 23:08:46,973] Trial 11 finished with value: 0.3302180685358255 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.024659223020607017, 'subsample': 0.6534203985145864, 'colsample_bytree': 0.8304015086422962}. Best is trial 10 with value: 0.3338469440164355.\n",
      "[I 2025-04-22 23:08:47,148] Trial 12 finished with value: 0.33051742344244983 and parameters: {'n_estimators': 83, 'max_depth': 4, 'learning_rate': 0.013524178373483697, 'subsample': 0.6921015565859585, 'colsample_bytree': 0.9706762530349121}. Best is trial 10 with value: 0.3338469440164355.\n",
      "[I 2025-04-22 23:08:47,317] Trial 13 finished with value: 0.33529097704217836 and parameters: {'n_estimators': 76, 'max_depth': 4, 'learning_rate': 0.045156006889493616, 'subsample': 0.6947942162333977, 'colsample_bytree': 0.9873255583246348}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:47,455] Trial 14 finished with value: 0.325 and parameters: {'n_estimators': 54, 'max_depth': 4, 'learning_rate': 0.05413508231175989, 'subsample': 0.6243831777679771, 'colsample_bytree': 0.9956269892399046}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:47,652] Trial 15 finished with value: 0.3038251366120218 and parameters: {'n_estimators': 132, 'max_depth': 3, 'learning_rate': 0.11286052145336453, 'subsample': 0.5581096899184019, 'colsample_bytree': 0.9168196360123275}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:47,848] Trial 16 finished with value: 0.32584916522740354 and parameters: {'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.04764884984815848, 'subsample': 0.7075505899448012, 'colsample_bytree': 0.8043310486627162}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:48,404] Trial 17 finished with value: 0.2727272727272727 and parameters: {'n_estimators': 132, 'max_depth': 8, 'learning_rate': 0.09413938694277954, 'subsample': 0.6594767170223366, 'colsample_bytree': 0.8941299985097494}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:48,591] Trial 18 finished with value: 0.32967032967032966 and parameters: {'n_estimators': 92, 'max_depth': 5, 'learning_rate': 0.04171763314727061, 'subsample': 0.9925315351124249, 'colsample_bytree': 0.9408560340773973}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:48,710] Trial 19 finished with value: 0.3311546840958606 and parameters: {'n_estimators': 52, 'max_depth': 4, 'learning_rate': 0.13106386225045982, 'subsample': 0.7838737099788166, 'colsample_bytree': 0.8692531327160546}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:48,958] Trial 20 finished with value: 0.28749028749028743 and parameters: {'n_estimators': 69, 'max_depth': 7, 'learning_rate': 0.19366011975140615, 'subsample': 0.7470298017801124, 'colsample_bytree': 0.9569574475647145}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:49,101] Trial 21 finished with value: 0.3182819383259912 and parameters: {'n_estimators': 61, 'max_depth': 4, 'learning_rate': 0.12955914937703036, 'subsample': 0.7968993802730016, 'colsample_bytree': 0.8726571669155051}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:49,219] Trial 22 finished with value: 0.3162393162393162 and parameters: {'n_estimators': 52, 'max_depth': 3, 'learning_rate': 0.28782836392969313, 'subsample': 0.6756175368238491, 'colsample_bytree': 0.7985443627915059}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:49,354] Trial 23 finished with value: 0.315847598012148 and parameters: {'n_estimators': 92, 'max_depth': 4, 'learning_rate': 0.07972785397533781, 'subsample': 0.7542063561676847, 'colsample_bytree': 0.8433491426665418}. Best is trial 13 with value: 0.33529097704217836.\n",
      "[I 2025-04-22 23:08:49,507] Trial 24 finished with value: 0.33871866295264624 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.03428465959362556, 'subsample': 0.594974012093731, 'colsample_bytree': 0.9934198543998869}. Best is trial 24 with value: 0.33871866295264624.\n",
      "[I 2025-04-22 23:08:49,673] Trial 25 finished with value: 0.33616298811544987 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.03422184241603851, 'subsample': 0.6169858726971553, 'colsample_bytree': 0.9967038947437423}. Best is trial 24 with value: 0.33871866295264624.\n",
      "[I 2025-04-22 23:08:49,838] Trial 26 finished with value: 0.3380900109769484 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.041123573754170986, 'subsample': 0.5986260150072205, 'colsample_bytree': 0.9951025163923856}. Best is trial 24 with value: 0.33871866295264624.\n",
      "[I 2025-04-22 23:08:50,126] Trial 27 finished with value: 0.29675638371290547 and parameters: {'n_estimators': 93, 'max_depth': 7, 'learning_rate': 0.03510453878713231, 'subsample': 0.5192461421519828, 'colsample_bytree': 0.94943850106614}. Best is trial 24 with value: 0.33871866295264624.\n",
      "[I 2025-04-22 23:08:50,342] Trial 28 finished with value: 0.3153320918684047 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.06984333266454901, 'subsample': 0.6020697697768631, 'colsample_bytree': 0.9980117266467934}. Best is trial 24 with value: 0.33871866295264624.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:50,475] Trial 29 finished with value: 0.30195381882770866 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.09815458451654753, 'subsample': 0.57266670522061, 'colsample_bytree': 0.9331474843181838}. Best is trial 24 with value: 0.33871866295264624.\n",
      "[I 2025-04-22 23:08:50,622] A new study created in memory with name: no-name-e2e2800b-6dcc-47c3-9c81-c316dec00151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_40_60: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.03428465959362556, 'subsample': 0.594974012093731, 'colsample_bytree': 0.9934198543998869, 'scale_pos_weight': 4.000418935902807}\n",
      "Accuracy:  0.6023\n",
      "Precision: 0.2538\n",
      "Recall:    0.5092\n",
      "F1-score:  0.3387\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.63      0.72      2388\n",
      "           1       0.25      0.51      0.34       597\n",
      "\n",
      "    accuracy                           0.60      2985\n",
      "   macro avg       0.54      0.57      0.53      2985\n",
      "weighted avg       0.72      0.60      0.64      2985\n",
      "\n",
      "\n",
      "=== Hiperparametry dla klasy: views_60_80 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:51,226] Trial 0 finished with value: 0.26904055390702275 and parameters: {'n_estimators': 159, 'max_depth': 9, 'learning_rate': 0.08066452467709553, 'subsample': 0.5687121590624664, 'colsample_bytree': 0.645584091600268}. Best is trial 0 with value: 0.26904055390702275.\n",
      "[I 2025-04-22 23:08:51,441] Trial 1 finished with value: 0.2885714285714286 and parameters: {'n_estimators': 75, 'max_depth': 7, 'learning_rate': 0.11005368809040711, 'subsample': 0.7683908533911564, 'colsample_bytree': 0.77173706800375}. Best is trial 1 with value: 0.2885714285714286.\n",
      "[I 2025-04-22 23:08:51,705] Trial 2 finished with value: 0.27297668038408773 and parameters: {'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.092122328363048, 'subsample': 0.8627961090378972, 'colsample_bytree': 0.9296266859019183}. Best is trial 1 with value: 0.2885714285714286.\n",
      "[I 2025-04-22 23:08:51,810] Trial 3 finished with value: 0.304152076038019 and parameters: {'n_estimators': 99, 'max_depth': 3, 'learning_rate': 0.14968849054542166, 'subsample': 0.9425511517934533, 'colsample_bytree': 0.5294472344336314}. Best is trial 3 with value: 0.304152076038019.\n",
      "[I 2025-04-22 23:08:51,934] Trial 4 finished with value: 0.29981261711430357 and parameters: {'n_estimators': 92, 'max_depth': 5, 'learning_rate': 0.18203285127118352, 'subsample': 0.9883778345047409, 'colsample_bytree': 0.561377609165473}. Best is trial 3 with value: 0.304152076038019.\n",
      "[I 2025-04-22 23:08:52,224] Trial 5 finished with value: 0.30431372549019603 and parameters: {'n_estimators': 188, 'max_depth': 5, 'learning_rate': 0.25794557902474435, 'subsample': 0.6735887239427938, 'colsample_bytree': 0.7611171183859498}. Best is trial 5 with value: 0.30431372549019603.\n",
      "[I 2025-04-22 23:08:52,377] Trial 6 finished with value: 0.29610046265697293 and parameters: {'n_estimators': 67, 'max_depth': 6, 'learning_rate': 0.1501107081516504, 'subsample': 0.6962648459117481, 'colsample_bytree': 0.6889223739306132}. Best is trial 5 with value: 0.30431372549019603.\n",
      "[I 2025-04-22 23:08:52,539] Trial 7 finished with value: 0.29844961240310075 and parameters: {'n_estimators': 87, 'max_depth': 6, 'learning_rate': 0.08316971457450775, 'subsample': 0.7669039336723165, 'colsample_bytree': 0.8917151412031623}. Best is trial 5 with value: 0.30431372549019603.\n",
      "[I 2025-04-22 23:08:53,143] Trial 8 finished with value: 0.2532188841201717 and parameters: {'n_estimators': 148, 'max_depth': 10, 'learning_rate': 0.13059963055744095, 'subsample': 0.5800818264910348, 'colsample_bytree': 0.504549170720687}. Best is trial 5 with value: 0.30431372549019603.\n",
      "[I 2025-04-22 23:08:53,443] Trial 9 finished with value: 0.2617801047120419 and parameters: {'n_estimators': 133, 'max_depth': 6, 'learning_rate': 0.2915959978137972, 'subsample': 0.8848811919928428, 'colsample_bytree': 0.9887228913429451}. Best is trial 5 with value: 0.30431372549019603.\n",
      "[I 2025-04-22 23:08:53,648] Trial 10 finished with value: 0.3039621525724423 and parameters: {'n_estimators': 198, 'max_depth': 3, 'learning_rate': 0.27522223460077133, 'subsample': 0.6905422587382624, 'colsample_bytree': 0.8104027398944449}. Best is trial 5 with value: 0.30431372549019603.\n",
      "[I 2025-04-22 23:08:53,784] Trial 11 finished with value: 0.31370449678800855 and parameters: {'n_estimators': 112, 'max_depth': 3, 'learning_rate': 0.21723448026720282, 'subsample': 0.9949073503212347, 'colsample_bytree': 0.6630738630861076}. Best is trial 11 with value: 0.31370449678800855.\n",
      "[I 2025-04-22 23:08:53,942] Trial 12 finished with value: 0.2999369880277253 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.2234052036031955, 'subsample': 0.6599340170180087, 'colsample_bytree': 0.6577036190061152}. Best is trial 11 with value: 0.31370449678800855.\n",
      "[I 2025-04-22 23:08:54,182] Trial 13 finished with value: 0.3168761220825853 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.016845726070977035, 'subsample': 0.8417397424341024, 'colsample_bytree': 0.7153926144962433}. Best is trial 13 with value: 0.3168761220825853.\n",
      "[I 2025-04-22 23:08:54,321] Trial 14 finished with value: 0.3307664099743307 and parameters: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.010669281094458926, 'subsample': 0.8428243880495053, 'colsample_bytree': 0.5998073754617418}. Best is trial 14 with value: 0.3307664099743307.\n",
      "[I 2025-04-22 23:08:54,447] Trial 15 finished with value: 0.3283227848101266 and parameters: {'n_estimators': 136, 'max_depth': 4, 'learning_rate': 0.012804429454892475, 'subsample': 0.8177760086436073, 'colsample_bytree': 0.5916540068678015}. Best is trial 14 with value: 0.3307664099743307.\n",
      "[I 2025-04-22 23:08:54,706] Trial 16 finished with value: 0.30287859824780977 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.017363011342172028, 'subsample': 0.8105778397037476, 'colsample_bytree': 0.5901708857617506}. Best is trial 14 with value: 0.3307664099743307.\n",
      "[I 2025-04-22 23:08:54,782] Trial 17 finished with value: 0.32957863996662495 and parameters: {'n_estimators': 55, 'max_depth': 4, 'learning_rate': 0.048314312247340854, 'subsample': 0.9127907568407632, 'colsample_bytree': 0.5984877323366049}. Best is trial 14 with value: 0.3307664099743307.\n",
      "[I 2025-04-22 23:08:54,853] Trial 18 finished with value: 0.3202391118701964 and parameters: {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.05972018543315302, 'subsample': 0.9134591486109711, 'colsample_bytree': 0.6098401210953976}. Best is trial 14 with value: 0.3307664099743307.\n",
      "[I 2025-04-22 23:08:54,928] Trial 19 finished with value: 0.33186725309876053 and parameters: {'n_estimators': 68, 'max_depth': 3, 'learning_rate': 0.048712608988892, 'subsample': 0.9342894797734363, 'colsample_bytree': 0.8304423419685262}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,076] Trial 20 finished with value: 0.31548311990686845 and parameters: {'n_estimators': 77, 'max_depth': 7, 'learning_rate': 0.04821469342170777, 'subsample': 0.9498026322993617, 'colsample_bytree': 0.8403692170695042}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,149] Trial 21 finished with value: 0.33012697191227397 and parameters: {'n_estimators': 55, 'max_depth': 3, 'learning_rate': 0.04931961832331232, 'subsample': 0.9037080231777107, 'colsample_bytree': 0.8547664239771725}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,226] Trial 22 finished with value: 0.3274268104776579 and parameters: {'n_estimators': 65, 'max_depth': 3, 'learning_rate': 0.04083393704867237, 'subsample': 0.888579599481853, 'colsample_bytree': 0.8600635571868583}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,322] Trial 23 finished with value: 0.31955922865013775 and parameters: {'n_estimators': 105, 'max_depth': 3, 'learning_rate': 0.06534222858830467, 'subsample': 0.9537156250532948, 'colsample_bytree': 0.9304557309715429}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,430] Trial 24 finished with value: 0.29568302779420463 and parameters: {'n_estimators': 85, 'max_depth': 5, 'learning_rate': 0.11101460659420907, 'subsample': 0.8080322038878535, 'colsample_bytree': 0.7995138811458882}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,510] Trial 25 finished with value: 0.3310759969902182 and parameters: {'n_estimators': 60, 'max_depth': 3, 'learning_rate': 0.034767675851383226, 'subsample': 0.8612580410203299, 'colsample_bytree': 0.730134472121089}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,623] Trial 26 finished with value: 0.3130755064456722 and parameters: {'n_estimators': 121, 'max_depth': 4, 'learning_rate': 0.03059776733520958, 'subsample': 0.7246985445891537, 'colsample_bytree': 0.7276382467907389}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,698] Trial 27 finished with value: 0.33150784958013874 and parameters: {'n_estimators': 74, 'max_depth': 3, 'learning_rate': 0.010184001480450868, 'subsample': 0.8451719464021419, 'colsample_bytree': 0.7035566336260005}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:55,800] Trial 28 finished with value: 0.2946573124662709 and parameters: {'n_estimators': 66, 'max_depth': 5, 'learning_rate': 0.0708420273961961, 'subsample': 0.7754616621101673, 'colsample_bytree': 0.7186085957711157}. Best is trial 19 with value: 0.33186725309876053.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:56,019] Trial 29 finished with value: 0.2828947368421053 and parameters: {'n_estimators': 78, 'max_depth': 9, 'learning_rate': 0.09803602264712055, 'subsample': 0.5175980844206278, 'colsample_bytree': 0.788015126515301}. Best is trial 19 with value: 0.33186725309876053.\n",
      "[I 2025-04-22 23:08:56,082] A new study created in memory with name: no-name-018810f9-5f84-4564-97d6-94c60e4e5df7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_60_80: {'n_estimators': 68, 'max_depth': 3, 'learning_rate': 0.048712608988892, 'subsample': 0.9342894797734363, 'colsample_bytree': 0.8304423419685262, 'scale_pos_weight': 4.000418935902807}\n",
      "Accuracy:  0.4402\n",
      "Precision: 0.2180\n",
      "Recall:    0.6951\n",
      "F1-score:  0.3319\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.38      0.52      2388\n",
      "           1       0.22      0.70      0.33       597\n",
      "\n",
      "    accuracy                           0.44      2985\n",
      "   macro avg       0.52      0.54      0.43      2985\n",
      "weighted avg       0.71      0.44      0.48      2985\n",
      "\n",
      "\n",
      "=== Hiperparametry dla klasy: views_80_100 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:08:56,295] Trial 0 finished with value: 0.3941267387944358 and parameters: {'n_estimators': 103, 'max_depth': 7, 'learning_rate': 0.18334160314708334, 'subsample': 0.6581467762043037, 'colsample_bytree': 0.8821850023335069}. Best is trial 0 with value: 0.3941267387944358.\n",
      "[I 2025-04-22 23:08:56,621] Trial 1 finished with value: 0.39078751857355126 and parameters: {'n_estimators': 184, 'max_depth': 6, 'learning_rate': 0.16005974566783435, 'subsample': 0.7699470761356251, 'colsample_bytree': 0.7816498609634486}. Best is trial 0 with value: 0.3941267387944358.\n",
      "[I 2025-04-22 23:08:57,180] Trial 2 finished with value: 0.3611911623439001 and parameters: {'n_estimators': 131, 'max_depth': 9, 'learning_rate': 0.2920378473061852, 'subsample': 0.5319889249524481, 'colsample_bytree': 0.942827509247585}. Best is trial 0 with value: 0.3941267387944358.\n",
      "[I 2025-04-22 23:08:57,737] Trial 3 finished with value: 0.4032023289665211 and parameters: {'n_estimators': 163, 'max_depth': 8, 'learning_rate': 0.055396116638210396, 'subsample': 0.6626678393193373, 'colsample_bytree': 0.8499180774511068}. Best is trial 3 with value: 0.4032023289665211.\n",
      "[I 2025-04-22 23:08:58,336] Trial 4 finished with value: 0.32770605759682225 and parameters: {'n_estimators': 183, 'max_depth': 8, 'learning_rate': 0.29506944112664935, 'subsample': 0.902688937121157, 'colsample_bytree': 0.9775887652821124}. Best is trial 3 with value: 0.4032023289665211.\n",
      "[I 2025-04-22 23:08:58,726] Trial 5 finished with value: 0.4072603516732841 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.012653444692443035, 'subsample': 0.5912658437293824, 'colsample_bytree': 0.8560323488171213}. Best is trial 5 with value: 0.4072603516732841.\n",
      "[I 2025-04-22 23:08:58,963] Trial 6 finished with value: 0.4049733570159858 and parameters: {'n_estimators': 152, 'max_depth': 5, 'learning_rate': 0.09824892058386768, 'subsample': 0.9724010178891023, 'colsample_bytree': 0.5084940320460456}. Best is trial 5 with value: 0.4072603516732841.\n",
      "[I 2025-04-22 23:08:59,400] Trial 7 finished with value: 0.41734019103600295 and parameters: {'n_estimators': 108, 'max_depth': 9, 'learning_rate': 0.04759838750132965, 'subsample': 0.8898605927835459, 'colsample_bytree': 0.6573232302050022}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:08:59,758] Trial 8 finished with value: 0.39778239778239777 and parameters: {'n_estimators': 106, 'max_depth': 8, 'learning_rate': 0.0716309880909712, 'subsample': 0.5489311359760638, 'colsample_bytree': 0.5026260769584114}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:00,404] Trial 9 finished with value: 0.3557692307692308 and parameters: {'n_estimators': 169, 'max_depth': 9, 'learning_rate': 0.1440076043403441, 'subsample': 0.9977225614567564, 'colsample_bytree': 0.9942139395785601}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:00,511] Trial 10 finished with value: 0.3956945156330087 and parameters: {'n_estimators': 55, 'max_depth': 3, 'learning_rate': 0.20914189237316683, 'subsample': 0.8259081299594284, 'colsample_bytree': 0.6475350098419518}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:01,014] Trial 11 finished with value: 0.411682892906815 and parameters: {'n_estimators': 79, 'max_depth': 10, 'learning_rate': 0.013744943402397866, 'subsample': 0.6648749234319221, 'colsample_bytree': 0.6829854134898745}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:01,439] Trial 12 finished with value: 0.4136090727151434 and parameters: {'n_estimators': 67, 'max_depth': 10, 'learning_rate': 0.01165848339699041, 'subsample': 0.8366294084624994, 'colsample_bytree': 0.6574881980902509}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:01,794] Trial 13 finished with value: 0.3949843260188088 and parameters: {'n_estimators': 54, 'max_depth': 10, 'learning_rate': 0.10370282488905966, 'subsample': 0.8705703881590166, 'colsample_bytree': 0.6119064688738168}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:02,308] Trial 14 finished with value: 0.40786598689002185 and parameters: {'n_estimators': 83, 'max_depth': 10, 'learning_rate': 0.042905070474100214, 'subsample': 0.8081174346809905, 'colsample_bytree': 0.706334099482509}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:02,768] Trial 15 finished with value: 0.4012738853503185 and parameters: {'n_estimators': 78, 'max_depth': 9, 'learning_rate': 0.09763916498733355, 'subsample': 0.9096538666400269, 'colsample_bytree': 0.579162169250062}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:03,015] Trial 16 finished with value: 0.3780645161290323 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.23736919654883665, 'subsample': 0.7314927290500677, 'colsample_bytree': 0.7432258188555584}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:03,836] Trial 17 finished with value: 0.4022082018927445 and parameters: {'n_estimators': 131, 'max_depth': 10, 'learning_rate': 0.03225175705079965, 'subsample': 0.9236260392629091, 'colsample_bytree': 0.5711150091851896}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:03,999] Trial 18 finished with value: 0.4050251256281407 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.0751999994648188, 'subsample': 0.835642256107141, 'colsample_bytree': 0.7837915156618653}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:04,389] Trial 19 finished with value: 0.3896713615023474 and parameters: {'n_estimators': 69, 'max_depth': 9, 'learning_rate': 0.12562941682534756, 'subsample': 0.7382166413150402, 'colsample_bytree': 0.6520009733124787}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:04,618] Trial 20 finished with value: 0.40637450199203184 and parameters: {'n_estimators': 97, 'max_depth': 6, 'learning_rate': 0.06655539257977587, 'subsample': 0.9513432898699784, 'colsample_bytree': 0.7354292591095747}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:05,089] Trial 21 finished with value: 0.41672378341329674 and parameters: {'n_estimators': 69, 'max_depth': 10, 'learning_rate': 0.01926468986394074, 'subsample': 0.6958068627158797, 'colsample_bytree': 0.6856357984846824}. Best is trial 7 with value: 0.41734019103600295.\n",
      "[I 2025-04-22 23:09:05,502] Trial 22 finished with value: 0.4185714285714286 and parameters: {'n_estimators': 66, 'max_depth': 10, 'learning_rate': 0.02958100254944465, 'subsample': 0.7758333298247789, 'colsample_bytree': 0.6737967178024702}. Best is trial 22 with value: 0.4185714285714286.\n",
      "[I 2025-04-22 23:09:05,753] Trial 23 finished with value: 0.40446487196323044 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.035005129200510424, 'subsample': 0.6908367866305439, 'colsample_bytree': 0.5939683074169138}. Best is trial 22 with value: 0.4185714285714286.\n",
      "[I 2025-04-22 23:09:06,152] Trial 24 finished with value: 0.4176117411607738 and parameters: {'n_estimators': 117, 'max_depth': 8, 'learning_rate': 0.04465021826774146, 'subsample': 0.7893549719536922, 'colsample_bytree': 0.7143525577252844}. Best is trial 22 with value: 0.4185714285714286.\n",
      "[I 2025-04-22 23:09:06,595] Trial 25 finished with value: 0.41160593792172734 and parameters: {'n_estimators': 118, 'max_depth': 8, 'learning_rate': 0.05221339269442943, 'subsample': 0.7800658705680655, 'colsample_bytree': 0.7862647261384186}. Best is trial 22 with value: 0.4185714285714286.\n",
      "[I 2025-04-22 23:09:06,944] Trial 26 finished with value: 0.4107512060647829 and parameters: {'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.08438370890461705, 'subsample': 0.8784662035043377, 'colsample_bytree': 0.5490808000257488}. Best is trial 22 with value: 0.4185714285714286.\n",
      "[I 2025-04-22 23:09:07,342] Trial 27 finished with value: 0.402555910543131 and parameters: {'n_estimators': 116, 'max_depth': 8, 'learning_rate': 0.12244058693341818, 'subsample': 0.792460048667572, 'colsample_bytree': 0.617064516686281}. Best is trial 22 with value: 0.4185714285714286.\n",
      "[I 2025-04-22 23:09:08,062] Trial 28 finished with value: 0.4131305044035228 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.04826185888648421, 'subsample': 0.8708562436004859, 'colsample_bytree': 0.7164454089228312}. Best is trial 22 with value: 0.4185714285714286.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:09:08,416] Trial 29 finished with value: 0.39550561797752803 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.16586459355356797, 'subsample': 0.7343858660585638, 'colsample_bytree': 0.824281502462038}. Best is trial 22 with value: 0.4185714285714286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_80_100: {'n_estimators': 66, 'max_depth': 10, 'learning_rate': 0.02958100254944465, 'subsample': 0.7758333298247789, 'colsample_bytree': 0.6737967178024702, 'scale_pos_weight': 4.000418935902807}\n",
      "Accuracy:  0.7273\n",
      "Precision: 0.3649\n",
      "Recall:    0.4908\n",
      "F1-score:  0.4186\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      2388\n",
      "           1       0.36      0.49      0.42       597\n",
      "\n",
      "    accuracy                           0.73      2985\n",
      "   macro avg       0.61      0.64      0.62      2985\n",
      "weighted avg       0.76      0.73      0.74      2985\n",
      "\n",
      "\n",
      "=== Najlepsze parametry dla każdej klasy ===\n",
      "views_0_20 -> {'n_estimators': 198, 'max_depth': 4, 'learning_rate': 0.03317687078146252, 'subsample': 0.7929167914981928, 'colsample_bytree': 0.8911686125271476, 'scale_pos_weight': 3.9983249581239533}\n",
      "views_20_40 -> {'n_estimators': 160, 'max_depth': 5, 'learning_rate': 0.08657582157191754, 'subsample': 0.7336754659978932, 'colsample_bytree': 0.7064510642114379, 'scale_pos_weight': 4.000418935902807}\n",
      "views_40_60 -> {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.03428465959362556, 'subsample': 0.594974012093731, 'colsample_bytree': 0.9934198543998869, 'scale_pos_weight': 4.000418935902807}\n",
      "views_60_80 -> {'n_estimators': 68, 'max_depth': 3, 'learning_rate': 0.048712608988892, 'subsample': 0.9342894797734363, 'colsample_bytree': 0.8304423419685262, 'scale_pos_weight': 4.000418935902807}\n",
      "views_80_100 -> {'n_estimators': 66, 'max_depth': 10, 'learning_rate': 0.02958100254944465, 'subsample': 0.7758333298247789, 'colsample_bytree': 0.6737967178024702, 'scale_pos_weight': 4.000418935902807}\n"
     ]
    }
   ],
   "source": [
    "# optymalizacja hiperparametrow i trenowanie na nich modelu\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "optuna_results = {}\n",
    "trained_models = {} # do przechowywania modeli juz wytrenowanych z tymi parametrami\n",
    "\n",
    "for col in percentile_cols:\n",
    "    print(f\"\\n=== Hiperparametry dla klasy: {col} ===\")\n",
    "    \n",
    "    X_train = splits[col]['X_train']\n",
    "    X_test = splits[col]['X_test']\n",
    "    y_train = splits[col]['y_train']\n",
    "    y_test = splits[col]['y_test']\n",
    "\n",
    "\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'scale_pos_weight': scale_pos_weight,  # <<< najważniejsza linijka\n",
    "        }\n",
    "\n",
    "        model = XGBClassifier(**params, eval_metric='logloss', random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        f1 = f1_score(y_test, preds, average='binary')  # wybieramy f1 bo mamy więcej zer od jedynek - niezbalansowane dane\n",
    "        return f1\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    optuna_results[col] = best_params\n",
    "\n",
    "    best_params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "    final_model = XGBClassifier(**best_params, eval_metric='logloss', random_state=42)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    trained_models[col] = final_model\n",
    "\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    final_acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "    print(f\"Najlepsze parametry dla {col}: {best_params}\")\n",
    "    print(f\"Accuracy:  {final_acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Najlepsze parametry dla każdej klasy ===\")\n",
    "for col, params in optuna_results.items():\n",
    "    print(f\"{col} -> {params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbd8df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:33:45,143] A new study created in memory with name: no-name-888bb75f-1b32-46f3-a0be-58e17d950316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hiperparametry dla klasy: views_0_20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:33:48,377] Trial 0 finished with value: 0.3371605121916078 and parameters: {'n_estimators': 127, 'max_depth': 9, 'learning_rate': 0.07227454438891792, 'subsample': 0.5082024768530444, 'colsample_bytree': 0.8142347272798356}. Best is trial 0 with value: 0.3371605121916078.\n",
      "[I 2025-04-22 23:33:49,560] Trial 1 finished with value: 0.34939605341430885 and parameters: {'n_estimators': 88, 'max_depth': 6, 'learning_rate': 0.24238707801581433, 'subsample': 0.8177858166004741, 'colsample_bytree': 0.5059656642789963}. Best is trial 1 with value: 0.34939605341430885.\n",
      "[I 2025-04-22 23:33:52,604] Trial 2 finished with value: 0.2938956253541096 and parameters: {'n_estimators': 85, 'max_depth': 10, 'learning_rate': 0.29888643783257435, 'subsample': 0.9527673727617545, 'colsample_bytree': 0.516776880216216}. Best is trial 1 with value: 0.34939605341430885.\n",
      "[I 2025-04-22 23:33:57,012] Trial 3 finished with value: 0.299154327457822 and parameters: {'n_estimators': 199, 'max_depth': 8, 'learning_rate': 0.18390802037109602, 'subsample': 0.6350547068397436, 'colsample_bytree': 0.7934458741923326}. Best is trial 1 with value: 0.34939605341430885.\n",
      "[I 2025-04-22 23:33:58,158] Trial 4 finished with value: 0.3627757461839428 and parameters: {'n_estimators': 152, 'max_depth': 4, 'learning_rate': 0.18323174278156892, 'subsample': 0.7517476965381558, 'colsample_bytree': 0.6900359708400168}. Best is trial 4 with value: 0.3627757461839428.\n",
      "[I 2025-04-22 23:34:00,235] Trial 5 finished with value: 0.3142858440396032 and parameters: {'n_estimators': 128, 'max_depth': 7, 'learning_rate': 0.2530162999906922, 'subsample': 0.9811086093131396, 'colsample_bytree': 0.5729316040574126}. Best is trial 4 with value: 0.3627757461839428.\n",
      "[I 2025-04-22 23:34:01,715] Trial 6 finished with value: 0.3500224768955535 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.28582359771247096, 'subsample': 0.9355647640939061, 'colsample_bytree': 0.6632805724444499}. Best is trial 4 with value: 0.3627757461839428.\n",
      "[I 2025-04-22 23:34:02,431] Trial 7 finished with value: 0.3735319100649304 and parameters: {'n_estimators': 76, 'max_depth': 4, 'learning_rate': 0.07562108100472271, 'subsample': 0.8184678961193028, 'colsample_bytree': 0.7004507175183177}. Best is trial 7 with value: 0.3735319100649304.\n",
      "[I 2025-04-22 23:34:03,690] Trial 8 finished with value: 0.3437169259505952 and parameters: {'n_estimators': 56, 'max_depth': 7, 'learning_rate': 0.25031702030426145, 'subsample': 0.5187338108308032, 'colsample_bytree': 0.8924271802762134}. Best is trial 7 with value: 0.3735319100649304.\n",
      "[I 2025-04-22 23:34:07,106] Trial 9 finished with value: 0.305993883500777 and parameters: {'n_estimators': 183, 'max_depth': 7, 'learning_rate': 0.23512815311072613, 'subsample': 0.7703484812491945, 'colsample_bytree': 0.8399738407932126}. Best is trial 7 with value: 0.3735319100649304.\n",
      "[I 2025-04-22 23:34:07,805] Trial 10 finished with value: 0.3729375895666885 and parameters: {'n_estimators': 51, 'max_depth': 3, 'learning_rate': 0.024562323693812893, 'subsample': 0.8651951481875336, 'colsample_bytree': 0.9894011882772529}. Best is trial 7 with value: 0.3735319100649304.\n",
      "[I 2025-04-22 23:34:08,429] Trial 11 finished with value: 0.3731631132917252 and parameters: {'n_estimators': 54, 'max_depth': 3, 'learning_rate': 0.019137434342607725, 'subsample': 0.8538623609392713, 'colsample_bytree': 0.9645325718795157}. Best is trial 7 with value: 0.3735319100649304.\n",
      "[I 2025-04-22 23:34:09,575] Trial 12 finished with value: 0.37199330041194056 and parameters: {'n_estimators': 84, 'max_depth': 5, 'learning_rate': 0.08299825119624658, 'subsample': 0.677634905185019, 'colsample_bytree': 0.9846369665691539}. Best is trial 7 with value: 0.3735319100649304.\n",
      "[I 2025-04-22 23:34:10,137] Trial 13 finished with value: 0.3705216439760023 and parameters: {'n_estimators': 74, 'max_depth': 3, 'learning_rate': 0.015134319432332094, 'subsample': 0.882809207966757, 'colsample_bytree': 0.7047361876109635}. Best is trial 7 with value: 0.3735319100649304.\n",
      "[I 2025-04-22 23:34:11,253] Trial 14 finished with value: 0.37441403528544676 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.08243907407080135, 'subsample': 0.6884552367329504, 'colsample_bytree': 0.9055991798701282}. Best is trial 14 with value: 0.37441403528544676.\n",
      "[I 2025-04-22 23:34:12,612] Trial 15 finished with value: 0.3648992621887679 and parameters: {'n_estimators': 109, 'max_depth': 5, 'learning_rate': 0.10641620650714406, 'subsample': 0.6657944681497526, 'colsample_bytree': 0.6204638072601872}. Best is trial 14 with value: 0.37441403528544676.\n",
      "[I 2025-04-22 23:34:14,056] Trial 16 finished with value: 0.3626304271910996 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.12876226440633257, 'subsample': 0.5925196630887546, 'colsample_bytree': 0.7440566049760692}. Best is trial 14 with value: 0.37441403528544676.\n",
      "[I 2025-04-22 23:34:15,824] Trial 17 finished with value: 0.3677340508900718 and parameters: {'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.06396268680067627, 'subsample': 0.7227774764850964, 'colsample_bytree': 0.9030676333670196}. Best is trial 14 with value: 0.37441403528544676.\n",
      "[I 2025-04-22 23:34:16,651] Trial 18 finished with value: 0.3760754774298948 and parameters: {'n_estimators': 105, 'max_depth': 4, 'learning_rate': 0.13712219666974257, 'subsample': 0.7849837999006687, 'colsample_bytree': 0.7578187783704511}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:17,703] Trial 19 finished with value: 0.3635575188939382 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.16642378412681225, 'subsample': 0.6066443787838901, 'colsample_bytree': 0.8868699194403932}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:18,772] Trial 20 finished with value: 0.3672818045366225 and parameters: {'n_estimators': 147, 'max_depth': 4, 'learning_rate': 0.13820385781634043, 'subsample': 0.7126362128734065, 'colsample_bytree': 0.7524765266855619}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:19,646] Trial 21 finished with value: 0.375455592827286 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.10233592656115242, 'subsample': 0.7965417378453504, 'colsample_bytree': 0.6313741128130068}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:20,954] Trial 22 finished with value: 0.3623194121676875 and parameters: {'n_estimators': 117, 'max_depth': 6, 'learning_rate': 0.10918932065813577, 'subsample': 0.7785741279543599, 'colsample_bytree': 0.601165971734841}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:22,016] Trial 23 finished with value: 0.37279974279592254 and parameters: {'n_estimators': 135, 'max_depth': 4, 'learning_rate': 0.04852352291778258, 'subsample': 0.8070426473725464, 'colsample_bytree': 0.6362988136965462}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:23,867] Trial 24 finished with value: 0.3714791468514623 and parameters: {'n_estimators': 168, 'max_depth': 5, 'learning_rate': 0.10073134678570941, 'subsample': 0.7023496297355198, 'colsample_bytree': 0.7542889481627121}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:24,741] Trial 25 finished with value: 0.36819993140210117 and parameters: {'n_estimators': 98, 'max_depth': 3, 'learning_rate': 0.14127483706342725, 'subsample': 0.9094280182368287, 'colsample_bytree': 0.5501791944462653}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:25,761] Trial 26 finished with value: 0.36276320947022617 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.20427556228125013, 'subsample': 0.7336177889546156, 'colsample_bytree': 0.9422557294720768}. Best is trial 18 with value: 0.3760754774298948.\n",
      "[I 2025-04-22 23:34:26,962] Trial 27 finished with value: 0.3822453190941879 and parameters: {'n_estimators': 93, 'max_depth': 6, 'learning_rate': 0.04128435392770395, 'subsample': 0.7865258711928674, 'colsample_bytree': 0.8429111980236967}. Best is trial 27 with value: 0.3822453190941879.\n",
      "[I 2025-04-22 23:34:28,790] Trial 28 finished with value: 0.3567609109731636 and parameters: {'n_estimators': 94, 'max_depth': 8, 'learning_rate': 0.05672658959373439, 'subsample': 0.7939157677771106, 'colsample_bytree': 0.8472905016029801}. Best is trial 27 with value: 0.3822453190941879.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:34:31,619] Trial 29 finished with value: 0.3545086614658556 and parameters: {'n_estimators': 72, 'max_depth': 10, 'learning_rate': 0.032639954174335184, 'subsample': 0.841016708410293, 'colsample_bytree': 0.8056969361756829}. Best is trial 27 with value: 0.3822453190941879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_0_20: {'n_estimators': 93, 'max_depth': 6, 'learning_rate': 0.04128435392770395, 'subsample': 0.7865258711928674, 'colsample_bytree': 0.8429111980236967, 'scale_pos_weight': 3.9986599664991624}\n",
      "Średni F1-score na 5 foldach: 0.3822\n",
      "Standardowe odchylenie F1-score: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:34:33,981] A new study created in memory with name: no-name-dd27f571-5f79-4c0c-8188-482235c4be05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia dokładność (accuracy) na 5 foldach: 0.7163\n",
      "\n",
      "=== Hiperparametry dla klasy: views_20_40 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:34:35,344] Trial 0 finished with value: 0.2636094649595674 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.2723823848517689, 'subsample': 0.7860161717019704, 'colsample_bytree': 0.8232806652796486}. Best is trial 0 with value: 0.2636094649595674.\n",
      "[I 2025-04-22 23:34:37,010] Trial 1 finished with value: 0.26667175949660205 and parameters: {'n_estimators': 176, 'max_depth': 6, 'learning_rate': 0.05372835855357048, 'subsample': 0.9170892390958632, 'colsample_bytree': 0.5383614819952642}. Best is trial 1 with value: 0.26667175949660205.\n",
      "[I 2025-04-22 23:34:37,815] Trial 2 finished with value: 0.27488541931895333 and parameters: {'n_estimators': 91, 'max_depth': 5, 'learning_rate': 0.11938323474073805, 'subsample': 0.9897854162935783, 'colsample_bytree': 0.5065049361761002}. Best is trial 2 with value: 0.27488541931895333.\n",
      "[I 2025-04-22 23:34:39,046] Trial 3 finished with value: 0.25507908541512536 and parameters: {'n_estimators': 65, 'max_depth': 7, 'learning_rate': 0.18993167762423252, 'subsample': 0.5337749883077412, 'colsample_bytree': 0.7604625433550626}. Best is trial 2 with value: 0.27488541931895333.\n",
      "[I 2025-04-22 23:34:41,071] Trial 4 finished with value: 0.22962380500054042 and parameters: {'n_estimators': 70, 'max_depth': 9, 'learning_rate': 0.2914976085321448, 'subsample': 0.7337584088845459, 'colsample_bytree': 0.5071292041828974}. Best is trial 2 with value: 0.27488541931895333.\n",
      "[I 2025-04-22 23:34:42,833] Trial 5 finished with value: 0.27165051379766875 and parameters: {'n_estimators': 154, 'max_depth': 6, 'learning_rate': 0.07037000932545448, 'subsample': 0.5544222373675556, 'colsample_bytree': 0.743975512424274}. Best is trial 2 with value: 0.27488541931895333.\n",
      "[I 2025-04-22 23:34:43,519] Trial 6 finished with value: 0.2761495313860817 and parameters: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.2241429256955829, 'subsample': 0.8928432644802151, 'colsample_bytree': 0.9198030050367071}. Best is trial 6 with value: 0.2761495313860817.\n",
      "[I 2025-04-22 23:34:47,302] Trial 7 finished with value: 0.19190195392116602 and parameters: {'n_estimators': 154, 'max_depth': 10, 'learning_rate': 0.12199322986050475, 'subsample': 0.9396414550146929, 'colsample_bytree': 0.5833581948913042}. Best is trial 6 with value: 0.2761495313860817.\n",
      "[I 2025-04-22 23:34:49,340] Trial 8 finished with value: 0.24498440787016626 and parameters: {'n_estimators': 184, 'max_depth': 6, 'learning_rate': 0.15679041893682255, 'subsample': 0.8867720227448119, 'colsample_bytree': 0.5383890066798075}. Best is trial 6 with value: 0.2761495313860817.\n",
      "[I 2025-04-22 23:34:50,201] Trial 9 finished with value: 0.29681099867849103 and parameters: {'n_estimators': 131, 'max_depth': 3, 'learning_rate': 0.09459392407019397, 'subsample': 0.6351921623698826, 'colsample_bytree': 0.723736380649896}. Best is trial 9 with value: 0.29681099867849103.\n",
      "[I 2025-04-22 23:34:50,898] Trial 10 finished with value: 0.3112907345908086 and parameters: {'n_estimators': 110, 'max_depth': 3, 'learning_rate': 0.021098576845443265, 'subsample': 0.6387364474533155, 'colsample_bytree': 0.63543547902585}. Best is trial 10 with value: 0.3112907345908086.\n",
      "[I 2025-04-22 23:34:51,721] Trial 11 finished with value: 0.3093658765964096 and parameters: {'n_estimators': 115, 'max_depth': 3, 'learning_rate': 0.02377130453109608, 'subsample': 0.6487891920270383, 'colsample_bytree': 0.6453497267922171}. Best is trial 10 with value: 0.3112907345908086.\n",
      "[I 2025-04-22 23:34:52,576] Trial 12 finished with value: 0.29949189929396874 and parameters: {'n_estimators': 101, 'max_depth': 4, 'learning_rate': 0.010539305152327844, 'subsample': 0.6632647136195611, 'colsample_bytree': 0.6497455378680898}. Best is trial 10 with value: 0.3112907345908086.\n",
      "[I 2025-04-22 23:34:53,410] Trial 13 finished with value: 0.31378918216392915 and parameters: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.01684165733866205, 'subsample': 0.6295171586755359, 'colsample_bytree': 0.6408007445579439}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:34:56,270] Trial 14 finished with value: 0.23561777793375632 and parameters: {'n_estimators': 140, 'max_depth': 8, 'learning_rate': 0.04838126688184831, 'subsample': 0.5861376625249348, 'colsample_bytree': 0.6556683390641417}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:34:57,267] Trial 15 finished with value: 0.2976559905016673 and parameters: {'n_estimators': 93, 'max_depth': 4, 'learning_rate': 0.08735805931359729, 'subsample': 0.735312304844203, 'colsample_bytree': 0.6042169996399366}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:34:58,253] Trial 16 finished with value: 0.2958850442757125 and parameters: {'n_estimators': 78, 'max_depth': 5, 'learning_rate': 0.010508067240343928, 'subsample': 0.8054980757393506, 'colsample_bytree': 0.8228923916450022}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:34:59,467] Trial 17 finished with value: 0.2832526642821621 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.05139929599708715, 'subsample': 0.6949956324570457, 'colsample_bytree': 0.9965336777200068}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:00,687] Trial 18 finished with value: 0.28843662300170453 and parameters: {'n_estimators': 143, 'max_depth': 3, 'learning_rate': 0.1477601774152339, 'subsample': 0.6005829527239859, 'colsample_bytree': 0.7034671731399142}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:01,747] Trial 19 finished with value: 0.2944124774832213 and parameters: {'n_estimators': 86, 'max_depth': 4, 'learning_rate': 0.0378538731543362, 'subsample': 0.5201036870839908, 'colsample_bytree': 0.5955130388520411}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:02,961] Trial 20 finished with value: 0.23693944339687914 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.2279053064171187, 'subsample': 0.8282253718922916, 'colsample_bytree': 0.8049152183322736}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:03,846] Trial 21 finished with value: 0.3122268693105585 and parameters: {'n_estimators': 113, 'max_depth': 3, 'learning_rate': 0.01621799549134387, 'subsample': 0.6788086525748115, 'colsample_bytree': 0.6712292034517571}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:04,696] Trial 22 finished with value: 0.304770410749592 and parameters: {'n_estimators': 125, 'max_depth': 3, 'learning_rate': 0.08085832811177099, 'subsample': 0.6919536476466818, 'colsample_bytree': 0.6856394353650249}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:05,584] Trial 23 finished with value: 0.29567971163621404 and parameters: {'n_estimators': 108, 'max_depth': 4, 'learning_rate': 0.03324352230595398, 'subsample': 0.602428087819725, 'colsample_bytree': 0.6166656679633812}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:06,750] Trial 24 finished with value: 0.28483963422440295 and parameters: {'n_estimators': 131, 'max_depth': 5, 'learning_rate': 0.06440802920393543, 'subsample': 0.6950071804480146, 'colsample_bytree': 0.6721975183773848}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:07,818] Trial 25 finished with value: 0.30177089296890613 and parameters: {'n_estimators': 166, 'max_depth': 3, 'learning_rate': 0.10418723872264399, 'subsample': 0.6289695443599007, 'colsample_bytree': 0.7718038582743036}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:08,626] Trial 26 finished with value: 0.29817148272049493 and parameters: {'n_estimators': 101, 'max_depth': 4, 'learning_rate': 0.031074667174352283, 'subsample': 0.5692527008724131, 'colsample_bytree': 0.5813644595937124}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:09,592] Trial 27 finished with value: 0.3076878461167703 and parameters: {'n_estimators': 142, 'max_depth': 3, 'learning_rate': 0.012160870210157014, 'subsample': 0.6741634472600648, 'colsample_bytree': 0.629372702720625}. Best is trial 13 with value: 0.31378918216392915.\n",
      "[I 2025-04-22 23:35:10,892] Trial 28 finished with value: 0.27987086182347304 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.06832573749814973, 'subsample': 0.7595579431355596, 'colsample_bytree': 0.7053084292583858}. Best is trial 13 with value: 0.31378918216392915.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:35:12,826] Trial 29 finished with value: 0.2772579143356687 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.24392374829192467, 'subsample': 0.7747367297194251, 'colsample_bytree': 0.8544412435576904}. Best is trial 13 with value: 0.31378918216392915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_20_40: {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.01684165733866205, 'subsample': 0.6295171586755359, 'colsample_bytree': 0.6408007445579439, 'scale_pos_weight': 4.000335120643432}\n",
      "Średni F1-score na 5 foldach: 0.3138\n",
      "Standardowe odchylenie F1-score: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:35:14,549] A new study created in memory with name: no-name-554816fd-07b1-4abb-8ddc-c91347d492f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia dokładność (accuracy) na 5 foldach: 0.5922\n",
      "\n",
      "=== Hiperparametry dla klasy: views_40_60 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:35:15,536] Trial 0 finished with value: 0.29592007587508595 and parameters: {'n_estimators': 154, 'max_depth': 3, 'learning_rate': 0.12563536815589754, 'subsample': 0.5243728578429776, 'colsample_bytree': 0.6759082617929385}. Best is trial 0 with value: 0.29592007587508595.\n",
      "[I 2025-04-22 23:35:17,099] Trial 1 finished with value: 0.23989552137038891 and parameters: {'n_estimators': 147, 'max_depth': 6, 'learning_rate': 0.2981512156544138, 'subsample': 0.8407308315571845, 'colsample_bytree': 0.9086173043324418}. Best is trial 0 with value: 0.29592007587508595.\n",
      "[I 2025-04-22 23:35:20,777] Trial 2 finished with value: 0.20504508040433606 and parameters: {'n_estimators': 176, 'max_depth': 9, 'learning_rate': 0.21216106818320318, 'subsample': 0.7131515347138528, 'colsample_bytree': 0.7839186231045573}. Best is trial 0 with value: 0.29592007587508595.\n",
      "[I 2025-04-22 23:35:24,956] Trial 3 finished with value: 0.23292256485107074 and parameters: {'n_estimators': 143, 'max_depth': 10, 'learning_rate': 0.022388075327988175, 'subsample': 0.7885378132907624, 'colsample_bytree': 0.7444233747466489}. Best is trial 0 with value: 0.29592007587508595.\n",
      "[I 2025-04-22 23:35:29,731] Trial 4 finished with value: 0.20026869920211907 and parameters: {'n_estimators': 162, 'max_depth': 10, 'learning_rate': 0.09811106390617869, 'subsample': 0.7071261715673784, 'colsample_bytree': 0.683932873480062}. Best is trial 0 with value: 0.29592007587508595.\n",
      "[I 2025-04-22 23:35:30,238] Trial 5 finished with value: 0.2986135650067814 and parameters: {'n_estimators': 68, 'max_depth': 3, 'learning_rate': 0.22403910259836537, 'subsample': 0.9069126327871819, 'colsample_bytree': 0.910100595037251}. Best is trial 5 with value: 0.2986135650067814.\n",
      "[I 2025-04-22 23:35:31,710] Trial 6 finished with value: 0.275791459951812 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.10946440860691807, 'subsample': 0.6092237851746938, 'colsample_bytree': 0.5293465107647441}. Best is trial 5 with value: 0.2986135650067814.\n",
      "[I 2025-04-22 23:35:32,345] Trial 7 finished with value: 0.28778343198205447 and parameters: {'n_estimators': 66, 'max_depth': 4, 'learning_rate': 0.21870003382401082, 'subsample': 0.9900237424682956, 'colsample_bytree': 0.8953991855627497}. Best is trial 5 with value: 0.2986135650067814.\n",
      "[I 2025-04-22 23:35:33,850] Trial 8 finished with value: 0.3012308726781105 and parameters: {'n_estimators': 156, 'max_depth': 5, 'learning_rate': 0.011139800450870235, 'subsample': 0.5913918110011194, 'colsample_bytree': 0.6799655651117518}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:39,073] Trial 9 finished with value: 0.20537554613973277 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.26083226339404264, 'subsample': 0.6751302807861885, 'colsample_bytree': 0.6750963906415229}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:40,990] Trial 10 finished with value: 0.2503300297564876 and parameters: {'n_estimators': 112, 'max_depth': 8, 'learning_rate': 0.024811246099642664, 'subsample': 0.5031374297340974, 'colsample_bytree': 0.5146694232233482}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:41,530] Trial 11 finished with value: 0.29604639285240963 and parameters: {'n_estimators': 56, 'max_depth': 4, 'learning_rate': 0.18465835561075064, 'subsample': 0.9340110257705987, 'colsample_bytree': 0.9970655990576804}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:42,428] Trial 12 finished with value: 0.29178107236729317 and parameters: {'n_estimators': 87, 'max_depth': 5, 'learning_rate': 0.06981366932453552, 'subsample': 0.8586532074729529, 'colsample_bytree': 0.8272002139693652}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:43,526] Trial 13 finished with value: 0.29260615760950187 and parameters: {'n_estimators': 125, 'max_depth': 3, 'learning_rate': 0.15088371245452106, 'subsample': 0.6087797638117014, 'colsample_bytree': 0.609218637246749}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:45,917] Trial 14 finished with value: 0.25842604466793884 and parameters: {'n_estimators': 199, 'max_depth': 5, 'learning_rate': 0.2406640628607705, 'subsample': 0.7878535397327837, 'colsample_bytree': 0.9968173020198138}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:47,289] Trial 15 finished with value: 0.248698945302351 and parameters: {'n_estimators': 81, 'max_depth': 7, 'learning_rate': 0.1788217443880447, 'subsample': 0.9068139380534312, 'colsample_bytree': 0.8857715561266768}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:48,250] Trial 16 finished with value: 0.2993564027806017 and parameters: {'n_estimators': 128, 'max_depth': 4, 'learning_rate': 0.06749235528428489, 'subsample': 0.6057760493875897, 'colsample_bytree': 0.6100046549009238}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:49,428] Trial 17 finished with value: 0.2856824343197282 and parameters: {'n_estimators': 132, 'max_depth': 5, 'learning_rate': 0.060813309790882925, 'subsample': 0.5971259160998249, 'colsample_bytree': 0.5798313791966303}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:50,962] Trial 18 finished with value: 0.26548820369109805 and parameters: {'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.05472898067560064, 'subsample': 0.5624203305757511, 'colsample_bytree': 0.6136453680310566}. Best is trial 8 with value: 0.3012308726781105.\n",
      "[I 2025-04-22 23:35:52,171] Trial 19 finished with value: 0.3053945673140147 and parameters: {'n_estimators': 167, 'max_depth': 4, 'learning_rate': 0.012142570008319913, 'subsample': 0.6527818989520823, 'colsample_bytree': 0.7322462632089609}. Best is trial 19 with value: 0.3053945673140147.\n",
      "[I 2025-04-22 23:35:54,197] Trial 20 finished with value: 0.2941977710779057 and parameters: {'n_estimators': 173, 'max_depth': 6, 'learning_rate': 0.01009764437707073, 'subsample': 0.6525091907388342, 'colsample_bytree': 0.735725878505681}. Best is trial 19 with value: 0.3053945673140147.\n",
      "[I 2025-04-22 23:35:55,229] Trial 21 finished with value: 0.30251760062572824 and parameters: {'n_estimators': 132, 'max_depth': 4, 'learning_rate': 0.04529691441219091, 'subsample': 0.6579232366142941, 'colsample_bytree': 0.6368019912807728}. Best is trial 19 with value: 0.3053945673140147.\n",
      "[I 2025-04-22 23:35:56,436] Trial 22 finished with value: 0.2992566224944384 and parameters: {'n_estimators': 164, 'max_depth': 4, 'learning_rate': 0.036602911680223366, 'subsample': 0.6535219796902587, 'colsample_bytree': 0.7059828841393394}. Best is trial 19 with value: 0.3053945673140147.\n",
      "[I 2025-04-22 23:35:57,753] Trial 23 finished with value: 0.28590751022576805 and parameters: {'n_estimators': 136, 'max_depth': 5, 'learning_rate': 0.045424992461653824, 'subsample': 0.5558947232140932, 'colsample_bytree': 0.8010567646074811}. Best is trial 19 with value: 0.3053945673140147.\n",
      "[I 2025-04-22 23:35:59,450] Trial 24 finished with value: 0.3106677185639396 and parameters: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.012198561429448971, 'subsample': 0.7409314167317517, 'colsample_bytree': 0.6597049937291706}. Best is trial 24 with value: 0.3106677185639396.\n",
      "[I 2025-04-22 23:36:00,923] Trial 25 finished with value: 0.29474054607923145 and parameters: {'n_estimators': 198, 'max_depth': 3, 'learning_rate': 0.09011102634797977, 'subsample': 0.7533019326996552, 'colsample_bytree': 0.6378335408959841}. Best is trial 24 with value: 0.3106677185639396.\n",
      "[I 2025-04-22 23:36:02,447] Trial 26 finished with value: 0.28725155519526663 and parameters: {'n_estimators': 184, 'max_depth': 4, 'learning_rate': 0.08296696958307279, 'subsample': 0.7215251860872417, 'colsample_bytree': 0.5455886373975262}. Best is trial 24 with value: 0.3106677185639396.\n",
      "[I 2025-04-22 23:36:03,999] Trial 27 finished with value: 0.2974932528730313 and parameters: {'n_estimators': 186, 'max_depth': 4, 'learning_rate': 0.03773517499355358, 'subsample': 0.7676546978568215, 'colsample_bytree': 0.5593644860425915}. Best is trial 24 with value: 0.3106677185639396.\n",
      "[I 2025-04-22 23:36:05,143] Trial 28 finished with value: 0.29199584515355187 and parameters: {'n_estimators': 172, 'max_depth': 3, 'learning_rate': 0.14097380909085322, 'subsample': 0.6783787832386269, 'colsample_bytree': 0.6388523150390334}. Best is trial 24 with value: 0.3106677185639396.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:36:06,285] Trial 29 finished with value: 0.2935777372312248 and parameters: {'n_estimators': 146, 'max_depth': 3, 'learning_rate': 0.11950392077007715, 'subsample': 0.8116458325468597, 'colsample_bytree': 0.7175146099432472}. Best is trial 24 with value: 0.3106677185639396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_40_60: {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.012198561429448971, 'subsample': 0.7409314167317517, 'colsample_bytree': 0.6597049937291706, 'scale_pos_weight': 4.000335120643432}\n",
      "Średni F1-score na 5 foldach: 0.3107\n",
      "Standardowe odchylenie F1-score: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:36:09,249] A new study created in memory with name: no-name-c4061dc4-cc10-487c-9572-50c9e2c5cdc7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia dokładność (accuracy) na 5 foldach: 0.5746\n",
      "\n",
      "=== Hiperparametry dla klasy: views_60_80 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:36:10,690] Trial 0 finished with value: 0.29051254714109176 and parameters: {'n_estimators': 181, 'max_depth': 5, 'learning_rate': 0.2271687173766215, 'subsample': 0.7464107816433752, 'colsample_bytree': 0.5600863903205073}. Best is trial 0 with value: 0.29051254714109176.\n",
      "[I 2025-04-22 23:36:12,084] Trial 1 finished with value: 0.2783583420579401 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.20925724481343191, 'subsample': 0.7822656646613386, 'colsample_bytree': 0.6734590090823275}. Best is trial 0 with value: 0.29051254714109176.\n",
      "[I 2025-04-22 23:36:12,853] Trial 2 finished with value: 0.31605278309705004 and parameters: {'n_estimators': 129, 'max_depth': 3, 'learning_rate': 0.27036603019873806, 'subsample': 0.959385486524067, 'colsample_bytree': 0.6114702902866145}. Best is trial 2 with value: 0.31605278309705004.\n",
      "[I 2025-04-22 23:36:13,571] Trial 3 finished with value: 0.30555708408382193 and parameters: {'n_estimators': 97, 'max_depth': 4, 'learning_rate': 0.2169251415912117, 'subsample': 0.6680381198996754, 'colsample_bytree': 0.7387972558048165}. Best is trial 2 with value: 0.31605278309705004.\n",
      "[I 2025-04-22 23:36:14,874] Trial 4 finished with value: 0.3030347875116402 and parameters: {'n_estimators': 94, 'max_depth': 6, 'learning_rate': 0.048780117537630945, 'subsample': 0.5325902896252083, 'colsample_bytree': 0.7788549953901395}. Best is trial 2 with value: 0.31605278309705004.\n",
      "[I 2025-04-22 23:36:19,200] Trial 5 finished with value: 0.23215593824182687 and parameters: {'n_estimators': 194, 'max_depth': 8, 'learning_rate': 0.21539604318288902, 'subsample': 0.6845205002436625, 'colsample_bytree': 0.895288495949551}. Best is trial 2 with value: 0.31605278309705004.\n",
      "[I 2025-04-22 23:36:21,493] Trial 6 finished with value: 0.24970930027952037 and parameters: {'n_estimators': 103, 'max_depth': 8, 'learning_rate': 0.18849099567187158, 'subsample': 0.6853259615929609, 'colsample_bytree': 0.7490307946436714}. Best is trial 2 with value: 0.31605278309705004.\n",
      "[I 2025-04-22 23:36:22,656] Trial 7 finished with value: 0.3185130736716465 and parameters: {'n_estimators': 140, 'max_depth': 4, 'learning_rate': 0.05136968992916421, 'subsample': 0.5325451018900047, 'colsample_bytree': 0.5672676425329544}. Best is trial 7 with value: 0.3185130736716465.\n",
      "[I 2025-04-22 23:36:24,097] Trial 8 finished with value: 0.31343824329138315 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.048545752363771615, 'subsample': 0.9590128678939889, 'colsample_bytree': 0.8719847652756362}. Best is trial 7 with value: 0.3185130736716465.\n",
      "[I 2025-04-22 23:36:28,577] Trial 9 finished with value: 0.24082508158969493 and parameters: {'n_estimators': 199, 'max_depth': 9, 'learning_rate': 0.05318697699745623, 'subsample': 0.6751473418379739, 'colsample_bytree': 0.5726565132813595}. Best is trial 7 with value: 0.3185130736716465.\n",
      "[I 2025-04-22 23:36:29,098] Trial 10 finished with value: 0.3211236175574614 and parameters: {'n_estimators': 54, 'max_depth': 3, 'learning_rate': 0.11411768878429707, 'subsample': 0.5088292412954084, 'colsample_bytree': 0.9778760556063677}. Best is trial 10 with value: 0.3211236175574614.\n",
      "[I 2025-04-22 23:36:29,648] Trial 11 finished with value: 0.3225486449512748 and parameters: {'n_estimators': 55, 'max_depth': 3, 'learning_rate': 0.11600711397960481, 'subsample': 0.5066841342059489, 'colsample_bytree': 0.979842113342138}. Best is trial 11 with value: 0.3225486449512748.\n",
      "[I 2025-04-22 23:36:30,132] Trial 12 finished with value: 0.32416059094369254 and parameters: {'n_estimators': 51, 'max_depth': 3, 'learning_rate': 0.12005380881274395, 'subsample': 0.5117010318936461, 'colsample_bytree': 0.9996627013081258}. Best is trial 12 with value: 0.32416059094369254.\n",
      "[I 2025-04-22 23:36:30,852] Trial 13 finished with value: 0.3299134757389071 and parameters: {'n_estimators': 55, 'max_depth': 3, 'learning_rate': 0.1219395015276925, 'subsample': 0.5868369451365202, 'colsample_bytree': 0.9969268407509077}. Best is trial 13 with value: 0.3299134757389071.\n",
      "[I 2025-04-22 23:36:31,868] Trial 14 finished with value: 0.3044659303929069 and parameters: {'n_estimators': 73, 'max_depth': 5, 'learning_rate': 0.11826408539966458, 'subsample': 0.5992261277473234, 'colsample_bytree': 0.8986079263133423}. Best is trial 13 with value: 0.3299134757389071.\n",
      "[I 2025-04-22 23:36:34,497] Trial 15 finished with value: 0.24296313302251424 and parameters: {'n_estimators': 71, 'max_depth': 10, 'learning_rate': 0.1557328369998589, 'subsample': 0.595634394084326, 'colsample_bytree': 0.9989964487901987}. Best is trial 13 with value: 0.3299134757389071.\n",
      "[I 2025-04-22 23:36:35,144] Trial 16 finished with value: 0.3168370652864082 and parameters: {'n_estimators': 75, 'max_depth': 4, 'learning_rate': 0.08430780791261797, 'subsample': 0.8610614765722662, 'colsample_bytree': 0.8413461206708832}. Best is trial 13 with value: 0.3299134757389071.\n",
      "[I 2025-04-22 23:36:36,891] Trial 17 finished with value: 0.2804858137479437 and parameters: {'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.1585890645808586, 'subsample': 0.5967788875454133, 'colsample_bytree': 0.9505019812750236}. Best is trial 13 with value: 0.3299134757389071.\n",
      "[I 2025-04-22 23:36:37,351] Trial 18 finished with value: 0.3380095115008065 and parameters: {'n_estimators': 52, 'max_depth': 3, 'learning_rate': 0.01934571903971341, 'subsample': 0.5791053743216948, 'colsample_bytree': 0.812828369644472}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:38,131] Trial 19 finished with value: 0.3345949943731609 and parameters: {'n_estimators': 82, 'max_depth': 4, 'learning_rate': 0.018619128046176464, 'subsample': 0.7627450132998046, 'colsample_bytree': 0.8153754769751707}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:39,095] Trial 20 finished with value: 0.3328142536851702 and parameters: {'n_estimators': 114, 'max_depth': 4, 'learning_rate': 0.015736645586049695, 'subsample': 0.8370118807512783, 'colsample_bytree': 0.8028619918630188}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:40,101] Trial 21 finished with value: 0.3367954977135857 and parameters: {'n_estimators': 117, 'max_depth': 4, 'learning_rate': 0.011072233953763798, 'subsample': 0.841338487719481, 'colsample_bytree': 0.8126729479294424}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:40,859] Trial 22 finished with value: 0.3313453515684014 and parameters: {'n_estimators': 79, 'max_depth': 5, 'learning_rate': 0.012198367508439195, 'subsample': 0.8663001278233194, 'colsample_bytree': 0.7098901258233241}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:41,728] Trial 23 finished with value: 0.3261089169384274 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.08254654209642062, 'subsample': 0.7846044248917496, 'colsample_bytree': 0.8116764615301983}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:42,724] Trial 24 finished with value: 0.3326505627495416 and parameters: {'n_estimators': 85, 'max_depth': 6, 'learning_rate': 0.021770301646961435, 'subsample': 0.8995970241296799, 'colsample_bytree': 0.849625337176395}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:43,328] Trial 25 finished with value: 0.3167941263181291 and parameters: {'n_estimators': 65, 'max_depth': 4, 'learning_rate': 0.07707508361928062, 'subsample': 0.735705856147436, 'colsample_bytree': 0.665116145601768}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:44,616] Trial 26 finished with value: 0.3175196535471689 and parameters: {'n_estimators': 160, 'max_depth': 5, 'learning_rate': 0.03642544867618103, 'subsample': 0.7958872000836542, 'colsample_bytree': 0.5075166101749806}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:45,211] Trial 27 finished with value: 0.32356758784673884 and parameters: {'n_estimators': 89, 'max_depth': 3, 'learning_rate': 0.07331395171673058, 'subsample': 0.7276810558209754, 'colsample_bytree': 0.9295087857486253}. Best is trial 18 with value: 0.3380095115008065.\n",
      "[I 2025-04-22 23:36:47,216] Trial 28 finished with value: 0.3078328393647118 and parameters: {'n_estimators': 111, 'max_depth': 7, 'learning_rate': 0.03537730851719474, 'subsample': 0.8148604940399284, 'colsample_bytree': 0.7830167489963719}. Best is trial 18 with value: 0.3380095115008065.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:36:48,928] Trial 29 finished with value: 0.29022312159558317 and parameters: {'n_estimators': 133, 'max_depth': 5, 'learning_rate': 0.29900793311377827, 'subsample': 0.9199483008776586, 'colsample_bytree': 0.840372509834204}. Best is trial 18 with value: 0.3380095115008065.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_60_80: {'n_estimators': 52, 'max_depth': 3, 'learning_rate': 0.01934571903971341, 'subsample': 0.5791053743216948, 'colsample_bytree': 0.812828369644472, 'scale_pos_weight': 4.000335120643432}\n",
      "Średni F1-score na 5 foldach: 0.3380\n",
      "Standardowe odchylenie F1-score: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:36:49,817] A new study created in memory with name: no-name-0d174498-ada4-43ca-8cdd-d673feaff026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia dokładność (accuracy) na 5 foldach: 0.4219\n",
      "\n",
      "=== Hiperparametry dla klasy: views_80_100 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:36:53,685] Trial 0 finished with value: 0.3179676601469757 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.2620186675804446, 'subsample': 0.6534999796882086, 'colsample_bytree': 0.7750521856116213}. Best is trial 0 with value: 0.3179676601469757.\n",
      "[I 2025-04-22 23:36:55,521] Trial 1 finished with value: 0.3552276040582233 and parameters: {'n_estimators': 135, 'max_depth': 7, 'learning_rate': 0.26242381552607236, 'subsample': 0.8829967540136254, 'colsample_bytree': 0.6150305059643911}. Best is trial 1 with value: 0.3552276040582233.\n",
      "[I 2025-04-22 23:36:58,389] Trial 2 finished with value: 0.3921776475582051 and parameters: {'n_estimators': 197, 'max_depth': 7, 'learning_rate': 0.05413485758915366, 'subsample': 0.6358489455840095, 'colsample_bytree': 0.7828435332539274}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:02,097] Trial 3 finished with value: 0.3692595358708347 and parameters: {'n_estimators': 171, 'max_depth': 9, 'learning_rate': 0.05871349254596741, 'subsample': 0.841556810602873, 'colsample_bytree': 0.7949726445100782}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:03,492] Trial 4 finished with value: 0.38788589708819415 and parameters: {'n_estimators': 199, 'max_depth': 3, 'learning_rate': 0.13699229371358432, 'subsample': 0.8956105508911554, 'colsample_bytree': 0.7800777664617979}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:06,836] Trial 5 finished with value: 0.3414697038691473 and parameters: {'n_estimators': 197, 'max_depth': 7, 'learning_rate': 0.22821958495611108, 'subsample': 0.6170669379178377, 'colsample_bytree': 0.7876363258814539}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:09,239] Trial 6 finished with value: 0.34392776899996547 and parameters: {'n_estimators': 109, 'max_depth': 8, 'learning_rate': 0.27080890053253676, 'subsample': 0.5575268681609313, 'colsample_bytree': 0.7844082389065429}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:10,962] Trial 7 finished with value: 0.36954183863953904 and parameters: {'n_estimators': 168, 'max_depth': 5, 'learning_rate': 0.19717361791951143, 'subsample': 0.784643118644648, 'colsample_bytree': 0.7268492500165442}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:15,005] Trial 8 finished with value: 0.31780618040360553 and parameters: {'n_estimators': 175, 'max_depth': 10, 'learning_rate': 0.19888675452836707, 'subsample': 0.7913934201711641, 'colsample_bytree': 0.5988925671295963}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:17,554] Trial 9 finished with value: 0.3556763727492685 and parameters: {'n_estimators': 152, 'max_depth': 8, 'learning_rate': 0.152238283081706, 'subsample': 0.7927409630619402, 'colsample_bytree': 0.7904628155296475}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:18,420] Trial 10 finished with value: 0.3812357623066715 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.010814721128073912, 'subsample': 0.6851614204751928, 'colsample_bytree': 0.9923483885028224}. Best is trial 2 with value: 0.3921776475582051.\n",
      "[I 2025-04-22 23:37:20,135] Trial 11 finished with value: 0.394775213676292 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.10349274520307832, 'subsample': 0.9784599849258582, 'colsample_bytree': 0.9175163799452837}. Best is trial 11 with value: 0.394775213676292.\n",
      "[I 2025-04-22 23:37:21,310] Trial 12 finished with value: 0.39497952851358303 and parameters: {'n_estimators': 96, 'max_depth': 5, 'learning_rate': 0.08055856348842982, 'subsample': 0.9690807260029879, 'colsample_bytree': 0.9787181840599151}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:21,899] Trial 13 finished with value: 0.3916529842369015 and parameters: {'n_estimators': 80, 'max_depth': 3, 'learning_rate': 0.11259720860219363, 'subsample': 0.970124891275971, 'colsample_bytree': 0.9851843913252074}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:22,969] Trial 14 finished with value: 0.3929107695084054 and parameters: {'n_estimators': 99, 'max_depth': 5, 'learning_rate': 0.09359919808274765, 'subsample': 0.9910623846293203, 'colsample_bytree': 0.9042228753633693}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:23,860] Trial 15 finished with value: 0.3888313997269918 and parameters: {'n_estimators': 126, 'max_depth': 4, 'learning_rate': 0.05635492481330094, 'subsample': 0.9327524651822998, 'colsample_bytree': 0.8989682328262548}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:24,388] Trial 16 finished with value: 0.38930510397543683 and parameters: {'n_estimators': 52, 'max_depth': 4, 'learning_rate': 0.09840487667227274, 'subsample': 0.9322474853841793, 'colsample_bytree': 0.9035836693269854}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:25,250] Trial 17 finished with value: 0.3793322328122598 and parameters: {'n_estimators': 102, 'max_depth': 4, 'learning_rate': 0.0119629433898443, 'subsample': 0.9997194457459098, 'colsample_bytree': 0.9432252361659539}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:26,327] Trial 18 finished with value: 0.3926719579761926 and parameters: {'n_estimators': 83, 'max_depth': 6, 'learning_rate': 0.18489997568723232, 'subsample': 0.8787610950161407, 'colsample_bytree': 0.5093725577931821}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:27,450] Trial 19 finished with value: 0.389091152449857 and parameters: {'n_estimators': 148, 'max_depth': 3, 'learning_rate': 0.13349318782368672, 'subsample': 0.7118430928865571, 'colsample_bytree': 0.8572004887958709}. Best is trial 12 with value: 0.39497952851358303.\n",
      "[I 2025-04-22 23:37:28,869] Trial 20 finished with value: 0.3958492139542057 and parameters: {'n_estimators': 114, 'max_depth': 6, 'learning_rate': 0.07619062333289243, 'subsample': 0.9406450056554772, 'colsample_bytree': 0.8536386276476418}. Best is trial 20 with value: 0.3958492139542057.\n",
      "[I 2025-04-22 23:37:30,242] Trial 21 finished with value: 0.3976232824569292 and parameters: {'n_estimators': 115, 'max_depth': 6, 'learning_rate': 0.07570690486115089, 'subsample': 0.94029800121382, 'colsample_bytree': 0.8592642219703969}. Best is trial 21 with value: 0.3976232824569292.\n",
      "[I 2025-04-22 23:37:31,527] Trial 22 finished with value: 0.397394386416127 and parameters: {'n_estimators': 114, 'max_depth': 6, 'learning_rate': 0.07204947021044464, 'subsample': 0.8433449579516268, 'colsample_bytree': 0.8517465595807268}. Best is trial 21 with value: 0.3976232824569292.\n",
      "[I 2025-04-22 23:37:32,913] Trial 23 finished with value: 0.39846154763050035 and parameters: {'n_estimators': 113, 'max_depth': 6, 'learning_rate': 0.0293128311295728, 'subsample': 0.8341098166539327, 'colsample_bytree': 0.8493312951254651}. Best is trial 23 with value: 0.39846154763050035.\n",
      "[I 2025-04-22 23:37:34,482] Trial 24 finished with value: 0.3979661715486126 and parameters: {'n_estimators': 123, 'max_depth': 6, 'learning_rate': 0.030367272080988925, 'subsample': 0.8567305041383083, 'colsample_bytree': 0.7136601852945937}. Best is trial 23 with value: 0.39846154763050035.\n",
      "[I 2025-04-22 23:37:37,653] Trial 25 finished with value: 0.4022643324307548 and parameters: {'n_estimators': 131, 'max_depth': 8, 'learning_rate': 0.0235083265958372, 'subsample': 0.8507604953242812, 'colsample_bytree': 0.7083209459963495}. Best is trial 25 with value: 0.4022643324307548.\n",
      "[I 2025-04-22 23:37:40,383] Trial 26 finished with value: 0.39661708181361066 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.0347540305468699, 'subsample': 0.8322076773544249, 'colsample_bytree': 0.7004939908250488}. Best is trial 25 with value: 0.4022643324307548.\n",
      "[I 2025-04-22 23:37:43,473] Trial 27 finished with value: 0.4047399134682525 and parameters: {'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.024142784689149564, 'subsample': 0.8250156574021353, 'colsample_bytree': 0.6592291024125524}. Best is trial 27 with value: 0.4047399134682525.\n",
      "[I 2025-04-22 23:37:46,797] Trial 28 finished with value: 0.3907713760814403 and parameters: {'n_estimators': 154, 'max_depth': 9, 'learning_rate': 0.030095433016697797, 'subsample': 0.7458562359707046, 'colsample_bytree': 0.6633614939767984}. Best is trial 27 with value: 0.4047399134682525.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-22 23:37:51,050] Trial 29 finished with value: 0.37421374263006746 and parameters: {'n_estimators': 142, 'max_depth': 10, 'learning_rate': 0.04124432741890985, 'subsample': 0.7633848627534144, 'colsample_bytree': 0.6543453639357092}. Best is trial 27 with value: 0.4047399134682525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla views_80_100: {'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.024142784689149564, 'subsample': 0.8250156574021353, 'colsample_bytree': 0.6592291024125524, 'scale_pos_weight': 4.000335120643432}\n",
      "Średni F1-score na 5 foldach: 0.4047\n",
      "Standardowe odchylenie F1-score: 0.0086\n",
      "Średnia dokładność (accuracy) na 5 foldach: 0.7187\n",
      "\n",
      "=== Najlepsze parametry dla każdej klasy ===\n",
      "views_0_20 -> {'n_estimators': 93, 'max_depth': 6, 'learning_rate': 0.04128435392770395, 'subsample': 0.7865258711928674, 'colsample_bytree': 0.8429111980236967, 'scale_pos_weight': 3.9986599664991624}\n",
      "views_20_40 -> {'n_estimators': 119, 'max_depth': 3, 'learning_rate': 0.01684165733866205, 'subsample': 0.6295171586755359, 'colsample_bytree': 0.6408007445579439, 'scale_pos_weight': 4.000335120643432}\n",
      "views_40_60 -> {'n_estimators': 190, 'max_depth': 4, 'learning_rate': 0.012198561429448971, 'subsample': 0.7409314167317517, 'colsample_bytree': 0.6597049937291706, 'scale_pos_weight': 4.000335120643432}\n",
      "views_60_80 -> {'n_estimators': 52, 'max_depth': 3, 'learning_rate': 0.01934571903971341, 'subsample': 0.5791053743216948, 'colsample_bytree': 0.812828369644472, 'scale_pos_weight': 4.000335120643432}\n",
      "views_80_100 -> {'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.024142784689149564, 'subsample': 0.8250156574021353, 'colsample_bytree': 0.6592291024125524, 'scale_pos_weight': 4.000335120643432}\n"
     ]
    }
   ],
   "source": [
    "# walidacja modelu - walidacja krzyżowa\n",
    "\n",
    "    # walidacja krzyżowa uwzględnia różnorodne podziały danych -> co sprawia, że wyniki są bardziej reprezentatywne\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "optuna_results = {}\n",
    "trained_models = {}  # do przechowywania modeli już wytrenowanych z tymi parametrami\n",
    "\n",
    "for col in percentile_cols:\n",
    "    print(f\"\\n=== Hiperparametry dla klasy: {col} ===\")\n",
    "    y_single = y_dict[col] \n",
    "\n",
    "    scale_pos_weight = len(y_single[y_single == 0]) / len(y_single[y_single == 1])\n",
    "    \n",
    "    X_train = splits[col]['X_train']\n",
    "    y_train = splits[col]['y_train']\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'scale_pos_weight': scale_pos_weight,  \n",
    "        }\n",
    "\n",
    "        model = XGBClassifier(**params, eval_metric='logloss', random_state=42)\n",
    "\n",
    "        f1_scores = cross_val_score(model, splits[col]['X_train'], splits[col]['y_train'], cv=5, scoring='f1')\n",
    "\n",
    "        return np.mean(f1_scores) \n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    optuna_results[col] = best_params\n",
    "\n",
    "    best_params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "    final_model = XGBClassifier(**best_params, eval_metric='logloss', random_state=42)\n",
    "\n",
    "    final_f1_scores = cross_val_score(final_model, X_train, y_train, cv=5, scoring='f1')\n",
    "    print(f\"Najlepsze parametry dla {col}: {best_params}\")\n",
    "    print(f\"Średni F1-score na 5 foldach: {np.mean(final_f1_scores):.4f}\")\n",
    "    print(f\"Standardowe odchylenie F1-score: {np.std(final_f1_scores):.4f}\")\n",
    "\n",
    "    final_acc_scores = cross_val_score(final_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Średnia dokładność (accuracy) na 5 foldach: {np.mean(final_acc_scores):.4f}\")\n",
    "    \n",
    "    \n",
    "print(\"\\n=== Najlepsze parametry dla każdej klasy ===\")\n",
    "for col, params in optuna_results.items():\n",
    "    print(f\"{col} -> {params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50e20629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('optuna_results.pkl', 'wb') as f:\n",
    "    pickle.dump(optuna_results, f)\n",
    "\n",
    "with open('trained_models.pkl', 'wb') as f:\n",
    "    pickle.dump(trained_models, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "850eab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('dane_Walidacyjne.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc242f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
